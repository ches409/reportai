import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict, field
from pathlib import Path
import logging
import re
import copy
from collections import Counter

# ë¼ì´ë¸ŒëŸ¬ë¦¬
from notion_client import AsyncClient as NotionClient
import httpx  # Ollama API í˜¸ì¶œìš©
import pandas as pd
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from weasyprint import HTML #pdfìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬
import zipfile
from cryptography.fernet import Fernet
import boto3
import requests
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel
import uvicorn
import logging
from dotenv import load_dotenv

import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from openpyxl.chart import BarChart, LineChart, Reference
from openpyxl.chart.label import DataLabelList

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("uvicorn")
logger.setLevel(logging.DEBUG)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
BASE_DIR = Path(__file__).resolve().parent
filter_select_prompt_path = BASE_DIR / "filter_select_prompt"
table_select_prompt_path = BASE_DIR / "table_select_prompt"

with filter_select_prompt_path.open("r", encoding="utf-8") as f:
    FILTER_SELECT_PROMPT = f.read()

with table_select_prompt_path.open("r", encoding="utf-8") as f:
    TABLE_SELECT_PROMPT = f.read()



class Config:
    NOTION_TOKEN: str = os.getenv("NOTION_TOKEN", "")

    DB_CLASS: str = os.getenv("DB_CLASS", "")
    DB_REPORTREQUEST: str = os.getenv("DB_REPORTREQUEST", "")
    DB_DISCHARGE: str = os.getenv("DB_DISCHARGE", "")
    DB_STUDENT: str = os.getenv("DB_STUDENT", "")

    OLLAMA_URL: str = os.getenv("OLLAMA_URL", "http://localhost:11434")
    OLLAMA_ENTITY_MODEL: str = os.getenv("OLLAMA_ENTITY_MODEL", "qwen3:8b")
    OLLAMA_QUERY_MODEL: str = os.getenv("OLLAMA_QUERY_MODEL", "qwencoder:7b")

    TEMP_DIR = Path("temp")
    REPORTS_DIR = Path("reports")
    #ENCRYPTION_KEY = os.getenv("ENCRYPTION_KEY", Fernet.generate_key())

    def __post_init__(self):
        self.TEMP_DIR.mkdir(exist_ok=True)
        self.REPORTS_DIR.mkdir(exist_ok=True)

config = Config()

#### ë°ì´í„° í´ë˜ìŠ¤ ì •ì˜

@dataclass
class Class:
    id: str
    student_name: str
    teacher_name: list[str]
    class_name: str
    parent_phone_number: str
    start_date: datetime
    school_name: str
    grade: int
    type: str  # íŠ¹ëª©, ë³¸ê´€ êµ¬ë¶„

@dataclass
class DISCHARGE:
    id: str
    student_name: str
    teacher_name: list[str]
    class_name: str
    parent_phone_number: str
    student_phone_number: str
    discharge_date: datetime
    start_date: datetime
    discharging_reason: str
    school_name: str
    grade: int
    type: str  # íŠ¹ëª©, ë³¸ê´€ êµ¬ë¶„



@dataclass
class ReportRequest:
    id: str
    question: str
    requester_name: str
    status: str  # ëŒ€ê¸°ì¤‘, ì²˜ë¦¬ì¤‘, ì™„ë£Œ, ì‹¤íŒ¨
    created_at: datetime
    updated_at: datetime

@dataclass
class ReportQuery:
    target_table: Optional[str] = None 
    filters: Dict[str, any] = field(default_factory=dict)
    columns: List[str] = field(default_factory=list)
    aggregations: Optional[List[str]] = None
    sort_by: Optional[str] = None
    date_range: Optional[Dict[str, str]] = None


####


class NotionManager:
    def __init__(self):
        self.client = NotionClient(auth=config.NOTION_TOKEN)
        self.db_map = {
            "class": config.DB_CLASS,
            "report_requests": config.DB_REPORTREQUEST,
            "discharge": config.DB_DISCHARGE,
            "student": config.DB_STUDENT
        }

    async def get_pending_requests(self) -> List[ReportRequest]:
        logger.info("ğŸ“‹ ë³´ê³ ì„œ ìš”ì²­ DB í™•ì¸ ì¤‘...")
    
        response = await self.client.databases.query(
            database_id=self.db_map["report_requests"],
            filter={
                "property": "ìƒíƒœ",
                "status": {"equals": "ëŒ€ê¸°ì¤‘"}
            }
        )

        requests = []
        for page in response["results"]:
            req = ReportRequest(
                id=page["id"],
                question=self._get_title(page, "ì§ˆë¬¸"),
                requester_name=self._get_person_name(page, "ìš”ì²­ì"),
                status="ëŒ€ê¸°ì¤‘",
                created_at=datetime.fromisoformat(page["created_time"].replace("Z", "+00:00")),
                updated_at=datetime.fromisoformat(page["last_edited_time"].replace("Z", "+00:00"))
            )
            requests.append(req)
        
        if requests:
            logger.info(f"âœ… {len(requests)}ê°œì˜ ìš”ì²­ ë°œê²¬")
        return requests
    
    async def query_table(self, table_name: str, query: ReportQuery) -> List[Dict]:
        logger.info(f"ğŸ“Š {table_name} í…Œì´ë¸” ì¡°íšŒ ì¤‘...")
        
        # allow case-insensitive table name lookup (AI may return 'Class' or 'DISCHARGE')
        db_id = self.db_map.get(table_name)
        if not db_id:
            db_id = self.db_map.get(table_name.lower())
        if not db_id:
            lower_map = {k.lower(): v for k, v in self.db_map.items()}
            db_id = lower_map.get(table_name.lower())
        if not db_id:
            logger.error(f"í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {table_name}")
            return []
        logger.debug(f"query_table: resolved '{table_name}' -> db_id '{db_id}'")
        
        # í•„í„° ìƒì„±
        notion_filter = self._build_filter(query)
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬: Notionì´ ê²°ê³¼ë¥¼ ì—¬ëŸ¬ í˜ì´ì§€ë¡œ ë°˜í™˜í•  ìˆ˜ ìˆìŒ
        all_results = []
        start_cursor = None
        while True:
            response = await self.client.databases.query(
                database_id=db_id,
                filter=notion_filter if notion_filter else None,
                start_cursor=start_cursor
            )
            results = response.get("results", [])
            all_results.extend(results)

            if not response.get("has_more"):
                break
            start_cursor = response.get("next_cursor")

        # ë°ì´í„° íŒŒì‹±
        data = []
        for page in all_results:
            row = {}
            for col in query.columns:
                row[col] = self._extract_property(page, col)
            data.append(row)
        
        # ë‚ ì§œ í•„í„° ì¶”ê°€ ì ìš© (Notion API í•„í„°ê°€ ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        if query.date_range and isinstance(query.date_range, dict) and query.date_range.get("property"):
            date_prop = query.date_range.get("property")
            start_val = query.date_range.get("start")
            end_val = query.date_range.get("end")
            
            if start_val or end_val:
                filtered_data = []
                for row in data:
                    date_str = row.get(date_prop, "")
                    if not date_str:
                        continue
                    
                    try:
                        # ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (ISO í˜•ì‹ ë˜ëŠ” YYYY-MM-DD)
                        if "T" in date_str:
                            row_date = datetime.fromisoformat(date_str.split("T")[0])
                        else:
                            row_date = datetime.fromisoformat(date_str)
                        
                        # ë‚ ì§œ ë²”ìœ„ ì²´í¬
                        if start_val:
                            start_date = datetime.fromisoformat(start_val)
                            if row_date < start_date:
                                continue
                        
                        if end_val:
                            end_date = datetime.fromisoformat(end_val)
                            if row_date > end_date:
                                continue
                        
                        filtered_data.append(row)
                    except Exception as e:
                        logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ (í–‰ ê±´ë„ˆëœ€): {date_str}, ì˜¤ë¥˜: {str(e)}")
                        continue
                
                logger.info(f"ğŸ“… ë‚ ì§œ í•„í„° ì ìš©: {len(data)}ê±´ â†’ {len(filtered_data)}ê±´ (ë²”ìœ„: {start_val} ~ {end_val})")
                data = filtered_data

        logger.info(f"âœ… {len(data)}ê±´ ì¡°íšŒ ì™„ë£Œ (pages: {len(all_results)})")
        return data
    

    async def query_multiple_tables(self, queries: List[ReportQuery]) -> Dict[str, List[Dict]]:
        # allow single ReportQuery or list of them
        if isinstance(queries, ReportQuery):
            queries = [queries]

        table_names = []
        for q in queries:
            try:
                table_names.append(str(q.target_table))
            except Exception:
                table_names.append("<unknown>")

        logger.info(f"ğŸ”— ë©€í‹° í…Œì´ë¸” ì¡°íšŒ: {', '.join(table_names)}")

        # ê° í…Œì´ë¸”ë³„ë¡œ ë°ì´í„° ì¡°íšŒ
        all_data = {}
        for query in queries:
            table_name = query.target_table
            # clone query per-table so we can inject a sensible default date property
            q_clone = copy.deepcopy(query)

            # If AI provided a date_range but omitted the property name, set per-table defaults
            if q_clone.date_range and isinstance(q_clone.date_range, dict) and not q_clone.date_range.get("property"):
                default_prop = None
                if str(table_name).lower() == "class":
                    default_prop = "start_date"
                elif str(table_name).lower() == "discharge":
                    default_prop = "discharge_date"

                if default_prop:
                    q_clone.date_range["property"] = default_prop
                    logger.debug(f"query_multiple_tables: set default date property '{default_prop}' for table '{table_name}'")

            data = await self.query_table(table_name, q_clone)
            all_data[table_name] = data

        # If only one table requested, return its data under its table name
        return all_data
    
    def _join_tables(self, all_data: Dict[str, List[Dict]], join_key: str) -> List[Dict]:
        logger.info(f"ğŸ”— ì¡°ì¸ í‚¤: {join_key}")
        
        # ì²« ë²ˆì§¸ í…Œì´ë¸”ì„ ê¸°ì¤€ìœ¼ë¡œ
        base_table = list(all_data.keys())[0]
        result = []
        
        for base_row in all_data[base_table]:
            joined_row = base_row.copy()
            join_value = base_row.get(join_key)
            
            if not join_value:
                result.append(joined_row)
                continue
            
            # ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ë§¤ì¹­ë˜ëŠ” ë°ì´í„° ì°¾ê¸°
            for table_name, table_data in all_data.items():
                if table_name == base_table:
                    continue
                
                # í•´ë‹¹ í…Œì´ë¸”ì—ì„œ ì¡°ì¸ í‚¤ ê°’ì´ ì¼ì¹˜í•˜ëŠ” í–‰ ì°¾ê¸°
                matching_rows = [
                    row for row in table_data 
                    if row.get(join_key) == join_value
                ]
                
                # ë§¤ì¹­ëœ ë°ì´í„° ë³‘í•© (ì»¬ëŸ¼ëª… ì¶©ëŒ ë°©ì§€)
                for match in matching_rows:
                    for key, value in match.items():
                        if key != join_key:  # ì¡°ì¸ í‚¤ëŠ” ì¤‘ë³µ ì œê±°
                            new_key = f"{table_name}_{key}"
                            joined_row[new_key] = value
            
            result.append(joined_row)
        
        logger.info(f"âœ… ì¡°ì¸ ì™„ë£Œ: {len(result)}ê±´")
        return result



    def _build_filter(self, query: ReportQuery) -> Optional[Dict]:
        conditions = []
        
        # ì¼ë°˜ í•„í„° ì²˜ë¦¬
        if query.filters:
            for key, value in query.filters.items():
                if isinstance(value, str):
                    conditions.append({
                        "property": key,
                        "rich_text": {"contains": value}
                    })
                elif isinstance(value, (int, float)):
                    conditions.append({
                        "property": key,
                        "number": {"equals": value}
                    })
                elif isinstance(value, list):
                    conditions.append({
                        "property": key,
                        "select": {"equals": value[0]}
                    })
        
        # ë‚ ì§œ í•„í„°ëŠ” query_tableì—ì„œ ì²˜ë¦¬ (Notion API í•„í„°ê°€ ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        
        # ì¡°ê±´ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ None ë°˜í™˜
        if len(conditions) == 0:
            return None
        elif len(conditions) > 1:
            return {"and": conditions}
        else:
            return conditions[0]
    
    async def update_request_status(self, request_id: str, status: str,
                                    error: str = None):
        properties = {
            "ìƒíƒœ": {"status": {"name": status}},
            "ì™„ë£Œì¼": {"date": {"start": datetime.now().isoformat()}}
        }        
        
        if error:
            properties["ë¹„ê³ "] = {
                "rich_text": [{"text": {"content": f"ì—ëŸ¬: {error}"}}]
            }
        
        await self.client.pages.update(page_id=request_id, properties=properties)
        logger.info(f"âœ… ìƒíƒœ ì—…ë°ì´íŠ¸: {status}")
    
    # í—¬í¼ ë©”ì„œë“œ
    def _get_title(self, page: Dict, prop: str) -> str:
        p = page["properties"].get(prop, {})
        return p["title"][0]["text"]["content"] if p.get("title") else ""
    
    def _get_person_name(self, page: Dict, prop: str) -> str:
        p = page["properties"].get(prop, {})
        return p["people"][0]["name"] if p.get("people") else ""
    
    def _get_person_email(self, page: Dict, prop: str) -> str:
        p = page["properties"].get(prop, {})
        return p["people"][0].get("person", {}).get("email", "") if p.get("people") else ""
    
    def _extract_property(self, page: Dict, prop: str):
        p = page["properties"].get(prop, {})
        prop_type = p.get("type", "")
        
        if prop_type == "title":
            return p["title"][0]["text"]["content"] if p.get("title") else ""
        elif prop_type == "rich_text":
            return p["rich_text"][0]["text"]["content"] if p.get("rich_text") else ""
        elif prop_type == "number":
            return p.get("number", 0)
        elif prop_type == "select":
            return p["select"]["name"] if p.get("select") else ""
        elif prop_type == "date":
            return p["date"]["start"] if p.get("date") else ""
        elif prop_type == "phone_number":
            return p.get("phone_number", "")
        return ""
    
    def _get_select(self, page: Dict, prop: str):
        p = page["properties"].get(prop, {})
        return p["select"]["name"] if p.get("select") else ""

    def _get_multi_select(self, page: Dict, prop: str):
        p = page["properties"].get(prop, {})
        return [v["name"] for v in p.get("multi_select", [])]

    def _get_number(self, page: Dict, prop: str):
        return page["properties"].get(prop, {}).get("number")

    def _get_date(self, page: Dict, prop: str):
        p = page["properties"].get(prop, {})
        return p["date"]["start"] if p.get("date") else None
    
    def _get_rich_text_value(self, page: Dict, prop: str) -> str:
        p = page["properties"].get(prop, {})
        if p.get("rich_text"):
            return p["rich_text"][0]["plain_text"].strip()
        return ""
    
    async def get_date_range_from_table(self, table_name: str, date_property: Optional[str] = None) -> Optional[Tuple[datetime, datetime]]:
        """í…Œì´ë¸”ì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¡°íšŒ (ì²« ë‚ ì§œì™€ ë§ˆì§€ë§‰ ë‚ ì§œ)
        
        Args:
            table_name: í…Œì´ë¸” ì´ë¦„ (class, discharge, student)
            date_property: ë‚ ì§œ ì†ì„±ëª… (Noneì´ë©´ ìë™ ê²°ì •)
                - class, student: start_date
                - discharge: discharge_date
        
        Returns:
            (ì²« ë‚ ì§œ, ë§ˆì§€ë§‰ ë‚ ì§œ) íŠœí”Œ ë˜ëŠ” None (ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°)
        """
        db_id = self.db_map.get(table_name.lower())
        if not db_id:
            logger.error(f"âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {table_name}")
            return None
        
        # ë‚ ì§œ ì†ì„± ìë™ ê²°ì •
        if not date_property:
            if table_name.lower() in ["class", "student"]:
                date_property = "start_date"
            elif table_name.lower() == "discharge":
                date_property = "discharge_date"
            else:
                logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í…Œì´ë¸” íƒ€ì…: {table_name}")
                return None
        
        try:
            # ì²« ë²ˆì§¸ ë‚ ì§œ ì¡°íšŒ (ì˜¤ë¦„ì°¨ìˆœ)
            first_result = await self.client.databases.query(
                database_id=db_id,
                sorts=[{"property": date_property, "direction": "ascending"}],
                page_size=1
            )
            
            # ë§ˆì§€ë§‰ ë‚ ì§œ ì¡°íšŒ (ë‚´ë¦¼ì°¨ìˆœ)
            last_result = await self.client.databases.query(
                database_id=db_id,
                sorts=[{"property": date_property, "direction": "descending"}],
                page_size=1
            )
            
            first_date = None
            last_date = None
            
            if first_result.get('results') and len(first_result['results']) > 0:
                first_date_str = self._get_date(first_result['results'][0], date_property)
                if first_date_str:
                    try:
                        if "T" in first_date_str:
                            first_date = datetime.fromisoformat(first_date_str.split("T")[0])
                        else:
                            first_date = datetime.fromisoformat(first_date_str)
                    except Exception as e:
                        logger.error(f"âŒ ì²« ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            if last_result.get('results') and len(last_result['results']) > 0:
                last_date_str = self._get_date(last_result['results'][0], date_property)
                if last_date_str:
                    try:
                        if "T" in last_date_str:
                            last_date = datetime.fromisoformat(last_date_str.split("T")[0])
                        else:
                            last_date = datetime.fromisoformat(last_date_str)
                    except Exception as e:
                        logger.error(f"âŒ ë§ˆì§€ë§‰ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            if first_date and last_date:
                logger.info(f"ğŸ“… [{table_name}] ë‚ ì§œ ë²”ìœ„: {first_date.date()} ~ {last_date.date()}")
                return (first_date, last_date)
            elif first_date:
                # ë°ì´í„°ê°€ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš°
                logger.info(f"ğŸ“… [{table_name}] ë‚ ì§œ: {first_date.date()}")
                return (first_date, first_date)
            else:
                logger.info(f"ğŸ“­ [{table_name}] í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ë‚ ì§œ ë²”ìœ„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None




####

class OllamaAnalyzer:
    def __init__(self):
        self.url = f"{config.OLLAMA_URL}/api/generate"
        self.model = config.OLLAMA_ENTITY_MODEL
    
    def _parse_date_range(self, question: str) -> Optional[Dict[str, str]]:
        """ì§ˆë¬¸ì—ì„œ ë‚ ì§œ ë²”ìœ„ë¥¼ íŒŒì‹±í•˜ì—¬ ë°˜í™˜"""
        question_lower = question.lower()
        now = datetime.now()
        
        # "Xë…„ Yì›”ë¶€í„° Zì›”ê¹Œì§€" í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "2025ë…„ 3ì›”ë¶€í„° 7ì›”ê¹Œì§€", "2025ë…„ ìœ í˜•ì‹  ì„ ìƒë‹˜ 3ì›”ë¶€í„° 7ì›”ê¹Œì§€")
        # ë” ìœ ì—°í•œ íŒ¨í„´: ë…„ë„ì™€ ì²« ë²ˆì§¸ ì›” ì‚¬ì´, "ë¶€í„°"ì™€ "ê¹Œì§€" ì‚¬ì´ì— ì–´ë–¤ í…ìŠ¤íŠ¸ê°€ ìˆì–´ë„ ë§¤ì¹­
        month_range_match = re.search(r'(\d{4})\s*ë…„.*?(\d{1,2})\s*ì›”\s*ë¶€í„°.*?(\d{1,2})\s*ì›”\s*ê¹Œì§€', question)
        if month_range_match:
            year = int(month_range_match.group(1))
            start_month = int(month_range_match.group(2))
            end_month = int(month_range_match.group(3))
            start_date = datetime(year, start_month, 1)
            # ì¢…ë£Œ ì›”ì˜ ë§ˆì§€ë§‰ ë‚  ê³„ì‚°
            if end_month == 12:
                end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
            else:
                end_date = datetime(year, end_month + 1, 1) - timedelta(days=1)
            result = {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
            logger.info(f"ğŸ“… ë‚ ì§œ ë²”ìœ„ íŒŒì‹± (ì›” ë²”ìœ„): {year}ë…„ {start_month}ì›” ~ {end_month}ì›” â†’ {result['start']} ~ {result['end']}")
            return result
        
        # "Xë…„ Yì›”ë¶€í„°" í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "2025ë…„ 3ì›”ë¶€í„°", "2025ë…„ ìœ í˜•ì‹  ì„ ìƒë‹˜ 3ì›”ë¶€í„°")
        # ë…„ë„ì™€ ì›” ì‚¬ì´ì— ì–´ë–¤ í…ìŠ¤íŠ¸ê°€ ìˆì–´ë„ ë§¤ì¹­
        month_start_match = re.search(r'(\d{4})\s*ë…„.*?(\d{1,2})\s*ì›”\s*ë¶€í„°', question)
        if month_start_match:
            year = int(month_start_match.group(1))
            start_month = int(month_start_match.group(2))
            start_date = datetime(year, start_month, 1)
            # í˜„ì¬ ë‚ ì§œê¹Œì§€ ë˜ëŠ” í•´ë‹¹ ë…„ë„ ë§ê¹Œì§€
            end_date = datetime(year, 12, 31)
            if year == now.year and start_month <= now.month:
                end_date = now
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        # "Xë…„ Yì›”" í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "2025ë…„ 3ì›”", "2025ë…„ ìœ í˜•ì‹  ì„ ìƒë‹˜ 3ì›”")
        # ë…„ë„ì™€ ì›” ì‚¬ì´ì— ì–´ë–¤ í…ìŠ¤íŠ¸ê°€ ìˆì–´ë„ ë§¤ì¹­ (ë‹¨, "ë¶€í„°"ë‚˜ "ê¹Œì§€"ê°€ ë°”ë¡œ ë’¤ì— ì˜¤ëŠ” ê²½ìš°ëŠ” ì œì™¸)
        single_month_match = re.search(r'(\d{4})\s*ë…„.*?(\d{1,2})\s*ì›”\s*(?!ë¶€í„°|ê¹Œì§€)', question)
        if single_month_match:
            year = int(single_month_match.group(1))
            month = int(single_month_match.group(2))
            start_date = datetime(year, month, 1)
            if month == 12:
                end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
            else:
                end_date = datetime(year, month + 1, 1) - timedelta(days=1)
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        # ë…„ë„ ì¶”ì¶œ (ì˜ˆ: "2024ë…„", "2023ë…„ë„") - ì›” ë²”ìœ„ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
        year_match = re.search(r'(\d{4})\s*ë…„(?!\s*\d)', question)
        if year_match:
            year = int(year_match.group(1))
            return {
                "start": f"{year}-01-01",
                "end": f"{year}-12-31"
            }
        
        # "ì˜¬í•´", "ì´ë²ˆ ë…„", "ì˜¬í•´ ì „ì²´"
        if any(keyword in question_lower for keyword in ["ì˜¬í•´", "ì´ë²ˆ ë…„", "ì˜¬í•´ ì „ì²´", "ì˜¬í•´ ì „ì²´"]):
            year = now.year
            return {
                "start": f"{year}-01-01",
                "end": f"{year}-12-31"
            }
        
        # "ì‘ë…„", "ì‘ë…„ë„"
        if any(keyword in question_lower for keyword in ["ì‘ë…„", "ì‘ë…„ë„"]):
            year = now.year - 1
            return {
                "start": f"{year}-01-01",
                "end": f"{year}-12-31"
            }
        
        # "ì´ë²ˆ ë‹¬", "ì´ë²ˆì›”", "ì´ë²ˆ ë‹¬", "ì´ë²ˆ ì›”"
        if any(keyword in question_lower for keyword in ["ì´ë²ˆ ë‹¬", "ì´ë²ˆì›”", "ì´ë²ˆ ë‹¬", "ì´ë²ˆ ì›”", "ì´ë²ˆë‹¬"]):
            year = now.year
            month = now.month
            start_date = datetime(year, month, 1)
            if month == 12:
                end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
            else:
                end_date = datetime(year, month + 1, 1) - timedelta(days=1)
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        # "ì§€ë‚œ ë‹¬", "ì§€ë‚œë‹¬", "ì €ë²ˆ ë‹¬"
        if any(keyword in question_lower for keyword in ["ì§€ë‚œ ë‹¬", "ì§€ë‚œë‹¬", "ì €ë²ˆ ë‹¬", "ì €ë²ˆë‹¬"]):
            if now.month == 1:
                year = now.year - 1
                month = 12
            else:
                year = now.year
                month = now.month - 1
            start_date = datetime(year, month, 1)
            if month == 12:
                end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
            else:
                end_date = datetime(year, month + 1, 1) - timedelta(days=1)
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        # "ìµœê·¼ Nê°œì›”", "ìµœê·¼ Në‹¬"
        recent_match = re.search(r'ìµœê·¼\s*(\d+)\s*ê°œ?ì›”', question_lower)
        if recent_match:
            months = int(recent_match.group(1))
            end_date = now
            start_date = now - timedelta(days=months * 30)
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        # "ìµœê·¼ Nì¼", "ìµœê·¼ Nì¼ê°„"
        days_match = re.search(r'ìµœê·¼\s*(\d+)\s*ì¼', question_lower)
        if days_match:
            days = int(days_match.group(1))
            end_date = now
            start_date = now - timedelta(days=days)
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        # "ì›”ë³„", "ì›”ë³„ í†µê³„", "ì›”ë³„ í˜„í™©" -> ìµœê·¼ 12ê°œì›”
        if any(keyword in question_lower for keyword in ["ì›”ë³„", "ì›”ë³„ í†µê³„", "ì›”ë³„ í˜„í™©", "ì›”ë³„ ì¶”ì´"]):
            end_date = now
            start_date = now - timedelta(days=365)  # ìµœê·¼ 12ê°œì›”
            return {
                "start": start_date.strftime("%Y-%m-%d"),
                "end": end_date.strftime("%Y-%m-%d")
            }
        
        
        
        # ê¸°ë³¸ê°’: ë‚ ì§œ ë²”ìœ„ ì—†ìŒ
        return None
    
    async def _call_ollama(self, prompt: str) -> str:
        """Ollama API í˜¸ì¶œ í—¬í¼ ë©”ì„œë“œ"""
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    self.url,
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False
                    },
                    timeout=30.0
                )
                result = response.json()
                return result.get("response", "").strip()
            except Exception as e:
                logger.error(f"âŒ Ollama API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
                raise
    
    def _parse_json_response(self, generated_text: str) -> Optional[Union[dict, list, str]]:
        """AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
        generated_text = generated_text.strip()
        
        # Try to decode the first JSON object in the model output robustly
        decoder = json.JSONDecoder()
        query_data = None
        
        try:
            obj, idx = decoder.raw_decode(generated_text)
            query_data = obj
        except ValueError:
            # fallback: try from first '{' or '['
            start = generated_text.find("{")
            if start == -1:
                start = generated_text.find("[")
            if start != -1:
                try:
                    obj, idx = decoder.raw_decode(generated_text[start:])
                    query_data = obj
                except Exception:
                    query_data = None

        # Additional heuristics: regex extract first {...} or [...] (DOTALL)
        if not query_data:
            try:
                m = re.search(r"(\{.*\}|\[.*\])", generated_text, re.DOTALL)
                if m:
                    candidate = m.group(1)
                    query_data = json.loads(candidate)
            except Exception:
                query_data = None

        # Try to repair common issues (single quotes, trailing commas)
        if not query_data:
            try:
                repaired = generated_text.replace("'", '"')
                repaired = re.sub(r",(\s*[}\]])", r"\1", repaired)
                m = re.search(r"(\{.*\}|\[.*\])", repaired, re.DOTALL)
                if m:
                    query_data = json.loads(m.group(1))
            except Exception:
                query_data = None
        
        return query_data
    
    async def _extract_filters(self, question: str) -> Dict[str, Any]:
        """1ë‹¨ê³„: í•„í„° ê°’ ì¶”ì¶œ"""
        logger.info("ğŸ” 1ë‹¨ê³„: í•„í„° ì¶”ì¶œ ì¤‘...")
        
        prompt = f"""{FILTER_SELECT_PROMPT}
ì§ˆë¬¸: {question}
"""
        
        try:
            response = await self._call_ollama(prompt)
            filters = self._parse_json_response(response)
            
            if isinstance(filters, dict):
                logger.info(f"âœ… í•„í„° ì¶”ì¶œ ì™„ë£Œ: {list(filters.keys())}")
                return filters
            else:
                logger.warning("âš ï¸ í•„í„° ì¶”ì¶œ ì‹¤íŒ¨, ë¹ˆ í•„í„° ë°˜í™˜")
                return {}
        except Exception as e:
            logger.error(f"âŒ í•„í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    async def _select_tables(self, question: str) -> Union[str, List[str]]:
        """2ë‹¨ê³„: í…Œì´ë¸” ìœ í˜• ì„ íƒ"""
        logger.info("ğŸ“‹ 2ë‹¨ê³„: í…Œì´ë¸” ì„ íƒ ì¤‘...")
        
        prompt = TABLE_SELECT_PROMPT.replace("{question}", question)
        
        try:
            response = await self._call_ollama(prompt)
            response = response.strip()
            logger.debug(f"í…Œì´ë¸” ì„ íƒ ì‘ë‹µ: {response}")
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ì‹œë„
            table_data = self._parse_json_response(response)
            if isinstance(table_data, list):
                # ë¦¬ìŠ¤íŠ¸ í˜•ì‹
                logger.info(f"âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: {table_data}")
                return table_data
            elif isinstance(table_data, str):
                # ë¬¸ìì—´ í˜•ì‹
                if table_data in ["class", "discharge"]:
                    logger.info(f"âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: {table_data}")
                    return table_data
            
            # ì§ì ‘ ë¬¸ìì—´ ë§¤ì¹­
            response_lower = response.lower()
            
            # "class", "discharge" ë‹¨ì¼ í…Œì´ë¸”
            if response_lower == "class" or (response_lower.startswith("class") and "discharge" not in response_lower):
                logger.info("âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: class")
                return "class"
            elif response_lower == "discharge" or (response_lower.startswith("discharge") and "class" not in response_lower):
                logger.info("âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: discharge")
                return "discharge"
            
            # "class"ì™€ "discharge" ë‘˜ ë‹¤ í¬í•¨ëœ ê²½ìš°
            if "class" in response_lower and "discharge" in response_lower:
                logger.info("âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: [class, discharge]")
                return ["class", "discharge"]
            
            # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ë¬¸ìì—´ íŒŒì‹± ì‹œë„
            if "[" in response and "]" in response:
                # "[class, discharge]" í˜•ì‹ ì¶”ì¶œ
                list_match = re.search(r'\[([^\]]+)\]', response)
                if list_match:
                    items = [item.strip().strip('"\'') for item in list_match.group(1).split(",")]
                    valid_items = [item for item in items if item in ["class", "discharge"]]
                    if len(valid_items) == 2:
                        logger.info("âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: [class, discharge]")
                        return ["class", "discharge"]
                    elif len(valid_items) == 1:
                        logger.info(f"âœ… í…Œì´ë¸” ì„ íƒ ì™„ë£Œ: {valid_items[0]}")
                        return valid_items[0]
            
            # ì§ˆë¬¸ ë‚´ìš© ê¸°ë°˜ ì¶”ë¡ 
            question_lower = question.lower()
            if any(keyword in question_lower for keyword in ["ì…í‡´ì†Œ", "ì…ì†Œ.*í‡´ì†Œ", "í‡´ì†Œ.*ì…ì†Œ"]):
                logger.info("âœ… ì§ˆë¬¸ ê¸°ë°˜ ì¶”ë¡ : [class, discharge]")
                return ["class", "discharge"]
            elif any(keyword in question_lower for keyword in ["í‡´ì†Œ", "í‡´ì›", "ì‚¬ìœ ", "ì¦ê°"]):
                logger.info("âœ… ì§ˆë¬¸ ê¸°ë°˜ ì¶”ë¡ : discharge")
                return "discharge"
            elif any(keyword in question_lower for keyword in ["ì…ì†Œ", "ì¬ì›", "í˜„ì¬ í•™ìƒ", "ë‹´ë‹¹ í•™ìƒ"]):
                logger.info("âœ… ì§ˆë¬¸ ê¸°ë°˜ ì¶”ë¡ : class")
                return "class"
            
            # ê¸°ë³¸ê°’: class
            logger.warning(f"âš ï¸ í…Œì´ë¸” ì„ íƒ ì‹¤íŒ¨ (ì‘ë‹µ: {response[:100]}), ê¸°ë³¸ê°’ 'class' ë°˜í™˜")
            return "class"
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ì„ íƒ ì‹¤íŒ¨: {str(e)}")
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ì§ˆë¬¸ ê¸°ë°˜ ì¶”ë¡ 
            question_lower = question.lower()
            if any(keyword in question_lower for keyword in ["ì…í‡´ì†Œ"]):
                return ["class", "discharge"]
            elif any(keyword in question_lower for keyword in ["í‡´ì†Œ", "í‡´ì›"]):
                return "discharge"
            return "class"
    
    def _extract_columns_from_question(self, question: str, table_type: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ ì¶”ì¶œ"""
        question_lower = question.lower()
        columns = []
        
        # ê¸°ë³¸ ì»¬ëŸ¼ (í•­ìƒ í¬í•¨)
        base_columns = ["student_name", "start_date", "grade", "class_name"]
        
        # í…Œì´ë¸”ë³„ ê¸°ë³¸ ì»¬ëŸ¼
        if table_type == "class":
            base_columns.extend(["student_name", "start_date", "grade", "class_name", "parent_phone_number"])
        elif table_type == "discharge":
            base_columns.extend(["student_name", "grade", "class_name", "discharge_date", "start_date", "discharging_reason", "parent_phone_number"])
        
        # ì§ˆë¬¸ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ì»¬ëŸ¼ í™•ì¸
        column_keywords = {
            "student_name": ["í•™ìƒëª…", "í•™ìƒ", "ì´ë¦„"],
            "teacher_name": ["ì„ ìƒë‹˜", "ë‹´ë‹¹", "ì›ì¥"],
            "class_name": ["ë°˜", "ìˆ˜ì—…", "ê³¼ëª©"],
            "grade": ["í•™ë…„"],
            "school_name": ["í•™êµ"],
            "start_date": ["ì…ì†Œì¼", "ì…ì†Œì¼ì", "ì‹œì‘ì¼"],
            "discharge_date": ["í‡´ì†Œì¼", "í‡´ì†Œì¼ì", "í‡´ì›ì¼"],
            "discharging_reason": ["ì‚¬ìœ ", "í‡´ì›ì‚¬ìœ ", "í‡´ì†Œì‚¬ìœ "],
            "parent_phone_number": ["ì „í™”", "ì—°ë½ì²˜", "í•™ë¶€ëª¨"]
        }
        
        # ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì»¬ëŸ¼ ì¶”ê°€
        for col, keywords in column_keywords.items():
            if any(keyword in question_lower for keyword in keywords):
                if col not in columns:
                    columns.append(col)
        
        # ê¸°ë³¸ ì»¬ëŸ¼ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        for col in base_columns:
            if col not in columns:
                columns.append(col)
        
        return columns
    
    def _determine_sort_by(self, question: str, table_type: str) -> Optional[str]:
        """ì •ë ¬ ê¸°ì¤€ ê²°ì •"""
        question_lower = question.lower()
        
        if table_type == "class":
            if any(keyword in question_lower for keyword in ["ì›”ë³„", "í†µê³„", "í˜„í™©", "ì¶”ì´"]):
                return "start_date"
            return "start_date"
        elif table_type == "discharge":
            if any(keyword in question_lower for keyword in ["ì›”ë³„", "í†µê³„", "í˜„í™©", "ì¶”ì´"]):
                return "discharge_date"
            return "discharge_date"
        
        return None
    
    def _determine_aggregations(self, question: str) -> Optional[List[str]]:
        """ì§‘ê³„ í•¨ìˆ˜ ê²°ì •"""
        question_lower = question.lower()
        
        if any(keyword in question_lower for keyword in ["ì›”ë³„", "í†µê³„", "í˜„í™©", "ì¶”ì´", "ìš”ì•½"]):
            return ["count_by_month"]
        
        return None
    
    def _generate_json_query(self, question: str, filters: Dict[str, Any], table_type: Union[str, List[str]]) -> Union[dict, list]:
        """3ë‹¨ê³„: ìµœì¢… JSON ì¿¼ë¦¬ ìƒì„± (ë¡œì§ ì²˜ë¦¬)"""
        logger.info("ğŸ“ 3ë‹¨ê³„: JSON ì¿¼ë¦¬ ìƒì„± ì¤‘...")
        
        # table_typeì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° í…Œì´ë¸”ì— ëŒ€í•´ ì¿¼ë¦¬ ìƒì„±
        if isinstance(table_type, list):
            queries = []
            for table in table_type:
                columns = self._extract_columns_from_question(question, table)
                sort_by = self._determine_sort_by(question, table)
                aggregations = self._determine_aggregations(question)
                
                query_obj = {
                    "target_table": table,
                    "filters": filters,
                    "columns": columns,
                    "aggregations": aggregations,
                    "sort_by": sort_by,
                    "date_range": None  # ë¡œì§ì—ì„œ ë‚˜ì¤‘ì— ì„¤ì •
                }
                queries.append(query_obj)
            
            logger.info(f"âœ… JSON ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(queries)}ê°œ ì¿¼ë¦¬")
            return queries
        
        # table_typeì´ ë¬¸ìì—´ì¸ ê²½ìš° ë‹¨ì¼ ì¿¼ë¦¬ ìƒì„±
        else:
            columns = self._extract_columns_from_question(question, table_type)
            sort_by = self._determine_sort_by(question, table_type)
            aggregations = self._determine_aggregations(question)
            
            query_obj = {
                "target_table": table_type,
                "filters": filters,
                "columns": columns,
                "aggregations": aggregations,
                "sort_by": sort_by,
                "date_range": None  # ë¡œì§ì—ì„œ ë‚˜ì¤‘ì— ì„¤ì •
            }
            
            logger.info("âœ… JSON ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ")
            return query_obj
    
    async def analyze_question(self, question: str) -> Union[ReportQuery, List[ReportQuery]]:
        """ìì—°ì–´ ì§ˆë¬¸ì„ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜ (3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤)"""
        logger.info(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘: {question[:50]}...")
        
        try:
            # 1ë‹¨ê³„: í•„í„° ì¶”ì¶œ
            filters = await self._extract_filters(question)
            
            # 2ë‹¨ê³„: í…Œì´ë¸” ì„ íƒ
            table_type = await self._select_tables(question)
            
            # 3ë‹¨ê³„: JSON ì¿¼ë¦¬ ìƒì„± (ë¡œì§ ì²˜ë¦¬, await ë¶ˆí•„ìš”)
            query_data = self._generate_json_query(question, filters, table_type)
            
            if not query_data or not isinstance(query_data, (dict, list)):
                logger.error("AI output (for debugging): %s", query_data)
                raise ValueError("JSON not found or invalid in model output")

            # ë‚ ì§œ ë²”ìœ„ë¥¼ ë¡œì§ìœ¼ë¡œ ê³„ì‚°
            parsed_date_range = self._parse_date_range(question)
            
            # If model returned a list of query objects, convert to list of ReportQuery
            if isinstance(query_data, list):
                queries = []
                for item in query_data:
                    if not isinstance(item, dict):
                        continue
                    target_table = item.get("target_table") or (item.get("target_tables", [None])[0] if isinstance(item.get("target_tables"), list) else item.get("target_tables"))
                    
                    # í…Œì´ë¸” íƒ€ì…ì— ë”°ë¼ ë‚ ì§œ ì†ì„± ì„¤ì •
                    date_range_with_property = None
                    if parsed_date_range:
                        date_range_with_property = parsed_date_range.copy()
                        if target_table == "class":
                            date_range_with_property["property"] = "start_date"
                        elif target_table == "discharge":
                            date_range_with_property["property"] = "discharge_date"
                    
                    q = ReportQuery(
                        target_table=target_table,
                        filters=item.get("filters", {}),
                        columns=item.get("columns", []),
                        aggregations=item.get("aggregations"),
                        date_range=date_range_with_property
                    )
                    queries.append(q)
                logger.info(f"âœ… ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {', '.join([str(q.target_table) for q in queries])} í…Œì´ë¸”")
                if parsed_date_range:
                    for q in queries:
                        if q.date_range:
                            logger.info(f"ğŸ“… {q.target_table} í…Œì´ë¸” ë‚ ì§œ ë²”ìœ„ ({q.date_range.get('property')}): {q.date_range['start']} ~ {q.date_range['end']}")
                return queries

            # Normalize target table(s) for single-object response
            target_table = query_data.get("target_table")
            if not target_table:
                tts = query_data.get("target_tables")
                if isinstance(tts, list) and tts:
                    target_table = tts[0]
                elif isinstance(tts, str):
                    target_table = tts

            # í…Œì´ë¸” íƒ€ì…ì— ë”°ë¼ ë‚ ì§œ ì†ì„± ì„¤ì •
            date_range_with_property = None
            if parsed_date_range:
                date_range_with_property = parsed_date_range.copy()
                if target_table == "class":
                    date_range_with_property["property"] = "start_date"
                elif target_table == "discharge":
                    date_range_with_property["property"] = "discharge_date"

            query = ReportQuery(
                target_table=target_table,
                filters=query_data.get("filters", {}),
                columns=query_data.get("columns", []),
                aggregations=query_data.get("aggregations"),
                date_range=date_range_with_property
            )

            logger.info(f"âœ… ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {query.target_table} í…Œì´ë¸”")
            if parsed_date_range:
                if query.date_range:
                    logger.info(f"ğŸ“… ë‚ ì§œ ë²”ìœ„ ({query.date_range.get('property')}): {query.date_range['start']} ~ {query.date_range['end']}")
            print(query)
            return query
                
        except Exception as e:
            logger.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            # ê¸°ë³¸ ì¿¼ë¦¬ ë°˜í™˜
            return ReportQuery(
                target_table="class",
                columns=["í•™ìƒëª…", "ë‹´ë‹¹", "ë°˜ëª…"]
            )


####
class ExcelFileHandler:
    """input í´ë”ì˜ ì—‘ì…€ íŒŒì¼ì„ ê°ì§€í•˜ê³  í´ë”ë³„ë¡œ êµ¬ë³„í•´ì„œ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, notion_manager: Optional[NotionManager] = None):
        self.input_dir = Path("input")
        self.processed_files = set()  # ì²˜ë¦¬ëœ íŒŒì¼ ì¶”ì  (ì¤‘ë³µ ë°©ì§€)
        self.queued_files = set()  # íì— ì¶”ê°€ëœ íŒŒì¼ ì¶”ì  (ì¤‘ë³µ í ì¶”ê°€ ë°©ì§€)
        self.table_folders = {
            "class": self.input_dir / "class",
            "discharge": self.input_dir / "discharge",
            "student": self.input_dir / "student"
        }
        # ê° í´ë”ë³„ë¡œ ì½ì€ íŒŒì¼ë“¤ì„ ì €ì¥
        self.stored_files = {
            "class": [],
            "discharge": [],
            "student": []
        }
        # ì „ì²˜ë¦¬ í•„í„° í‚¤ì›Œë“œ (ë°˜ëª…ì— í¬í•¨ë˜ë©´ ì œê±°)
        self.filter_keywords = ["TEST", "ë©´ì ‘", "ìì†Œì„œ", "ìƒë‹´", "ëŒ€ì…"]
        # NotionManager (ë‚ ì§œ ë²”ìœ„ ì¡°íšŒìš©)
        self.notion = notion_manager
    
    def _read_excel_file(self, file_path: Path) -> Optional[pd.DataFrame]:
        """ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜ (ë¹ˆ í–‰ ì œì™¸)"""
        try:
            logger.info(f"ğŸ“– ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹œì‘: {file_path.name}")
            
            # ì—‘ì…€ íŒŒì¼ ì½ê¸°
            df = pd.read_excel(file_path)
            
            if df.empty:
                logger.warning(f"âš ï¸ ë¹ˆ ì—‘ì…€ íŒŒì¼: {file_path.name}")
                return None
            
            # ë¹ˆ í–‰ ì œê±° (ëª¨ë“  ì»¬ëŸ¼ì´ NaNì¸ í–‰)
            before_count = len(df)
            df = df.dropna(how='all')  # ëª¨ë“  ê°’ì´ NaNì¸ í–‰ ì œê±°
            
            if len(df) < before_count:
                logger.info(f"ğŸ—‘ï¸ ë¹ˆ í–‰ {before_count - len(df)}ê°œ ì œê±°ë¨")
            
            # ë¹ˆ ì—´ ì œê±° (ëª¨ë“  ê°’ì´ NaNì¸ ì—´)
            df = df.dropna(axis=1, how='all')
            
            if df.empty:
                logger.warning(f"âš ï¸ ë¹ˆ í–‰ ì œê±° í›„ ë°ì´í„°ê°€ ì—†ìŒ: {file_path.name}")
                return None
            
            logger.info(f"âœ… ì—‘ì…€ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {file_path.name} ({len(df)}ê°œ í–‰)")
            return df
            
        except Exception as e:
            logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path.name}, ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def watch_and_store(self) -> Dict[str, List[Dict[str, Any]]]:
        """input í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ ìƒˆ ì—‘ì…€ íŒŒì¼ì„ ê°ì§€í•˜ê³  í´ë”ë³„ë¡œ êµ¬ë³„í•´ì„œ ì €ì¥
        
        Returns:
            Dict[str, List[Dict]]: í´ë”ë³„ë¡œ ì €ì¥ëœ íŒŒì¼ ì •ë³´
                ì˜ˆ: {
                    "class": [
                        {"file_name": "class1.xlsx", "file_path": "input/class/class1.xlsx", "dataframe": df1},
                        {"file_name": "class2.xlsx", "file_path": "input/class/class2.xlsx", "dataframe": df2}
                    ],
                    "discharge": [
                        {"file_name": "discharge1.xlsx", "file_path": "input/discharge/discharge1.xlsx", "dataframe": df3}
                    ],
                    "student": []
                }
        """
        # input í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not self.input_dir.exists():
            self.input_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ input í´ë” ìƒì„±: {self.input_dir}")
        
        new_files_count = 0
        
        # ê° í…Œì´ë¸”ë³„ í´ë” í™•ì¸ ë° íŒŒì¼ ì½ê¸°
        for table_type, folder_path in self.table_folders.items():
            logger.info(f"ğŸ“‚ [{table_type}] í´ë” ìŠ¤ìº” ì¤‘: {folder_path}")
            
            if not folder_path.exists():
                folder_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"ğŸ“ {table_type} í´ë” ìƒì„±: {folder_path}")
                continue
            
            # ì—‘ì…€ íŒŒì¼ ì°¾ê¸°
            excel_files = list(folder_path.glob("*.xlsx")) + list(folder_path.glob("*.xls"))
            logger.info(f"ğŸ“‹ [{table_type}] í´ë”ì—ì„œ {len(excel_files)}ê°œ ì—‘ì…€ íŒŒì¼ ë°œê²¬")
            
            for excel_file in excel_files:
                # íŒŒì¼ ê²½ë¡œë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬ ì—¬ë¶€ í™•ì¸
                file_key = str(excel_file.resolve())
                
                # ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆê±°ë‚˜ íì— ì¶”ê°€ëœ íŒŒì¼ì€ ê±´ë„ˆëœ€
                if file_key in self.processed_files:
                    logger.debug(f"â­ï¸ [{table_type}] ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ê±´ë„ˆëœ€: {excel_file.name}")
                    continue
                
                if file_key in self.queued_files:
                    logger.debug(f"â­ï¸ [{table_type}] ì´ë¯¸ íì— ì¶”ê°€ëœ íŒŒì¼ ê±´ë„ˆëœ€: {excel_file.name}")
                    continue
                
                # ì´ë¯¸ stored_filesì— ìˆëŠ” íŒŒì¼ì¸ì§€ í™•ì¸ (ê°™ì€ íŒŒì¼ì´ ì—¬ëŸ¬ ë²ˆ ìŠ¤ìº”ë˜ëŠ” ê²ƒ ë°©ì§€)
                already_stored = False
                for stored_file in self.stored_files[table_type]:
                    if stored_file.get("file_key") == file_key:
                        already_stored = True
                        break
                
                if already_stored:
                    logger.debug(f"â­ï¸ [{table_type}] ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ ê±´ë„ˆëœ€: {excel_file.name}")
                    continue
                
                # ì—‘ì…€ íŒŒì¼ ì½ê¸°
                df = self._read_excel_file(excel_file)
                
                if df is not None:
                    # ìƒëŒ€ ê²½ë¡œ ìƒì„± (ì•ˆì „í•˜ê²Œ)
                    try:
                        file_path_str = str(excel_file.resolve().relative_to(Path.cwd().resolve()))
                    except ValueError:
                        # ìƒëŒ€ ê²½ë¡œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                        file_path_str = str(excel_file.resolve())
                    
                    file_info = {
                        "file_name": excel_file.name,
                        "file_path": file_path_str,
                        "file_key": file_key,  # íŒŒì¼ í‚¤ ì¶”ê°€
                        "folder": table_type,
                        "dataframe": df,
                        "rows": len(df),
                        "columns": list(df.columns),
                        "read_time": datetime.now().isoformat()
                    }
                    # í´ë”ë³„ë¡œ êµ¬ë³„í•´ì„œ ì €ì¥
                    self.stored_files[table_type].append(file_info)
                    # íŒŒì¼ì„ ì½ì€ ì¦‰ì‹œ processed_filesì— ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ ìŠ¤ìº”ì—ì„œ ê±´ë„ˆë›°ë„ë¡ í•¨
                    # (íŒŒì¼ ì´ë™ í›„ì—ë„ ë‹¤ì‹œ ì¶”ê°€ë˜ì§€ë§Œ, ì´ë¯¸ processed_filesì— ìˆìœ¼ë©´ ê±´ë„ˆëœ€)
                    self.processed_files.add(file_key)
                    new_files_count += 1
                    logger.info(f"âœ… [{table_type}] íŒŒì¼ ì €ì¥ ì™„ë£Œ: {excel_file.name} ({len(df)}ê°œ í–‰)")
                else:
                    logger.warning(f"âš ï¸ [{table_type}] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {excel_file.name}")
        
        # í´ë”ë³„ ìš”ì•½ ë¡œê·¸
        for table_type, files in self.stored_files.items():
            if files:
                logger.info(f"ğŸ“Š [{table_type}] í´ë”: ì´ {len(files)}ê°œ íŒŒì¼ ì €ì¥ë¨")
        
        if new_files_count > 0:
            logger.info(f"ğŸ‰ ìƒˆë¡œ ê°ì§€ëœ íŒŒì¼: {new_files_count}ê°œ")
        else:
            logger.info("ğŸ’¤ ìƒˆë¡œìš´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return self.stored_files
    
    async def preprocess_and_merge(self, table_type: str) -> Optional[pd.DataFrame]:
        """ì €ì¥ëœ íŒŒì¼ë“¤ì„ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±° ë° ë‚ ì§œ í•„í„°ë§
        
        Args:
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
        
        Returns:
            ì „ì²˜ë¦¬ëœ DataFrame (í•©ì³ì§€ê³  ì¤‘ë³µ ì œê±°, ë‚ ì§œ í•„í„°ë§ë¨) ë˜ëŠ” None
        """
        if table_type not in self.stored_files:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í…Œì´ë¸” íƒ€ì…: {table_type}")
            return None
        
        file_list = self.stored_files[table_type]
        
        if not file_list:
            logger.warning(f"âš ï¸ [{table_type}] í´ë”ì— ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        logger.info(f"ğŸ”„ [{table_type}] ì „ì²˜ë¦¬ ì‹œì‘: {len(file_list)}ê°œ íŒŒì¼ í•©ì¹˜ê¸°")
        
        # ëª¨ë“  DataFrame í•©ì¹˜ê¸°
        dataframes = []
        for file_info in file_list:
            df = file_info.get("dataframe")
            if df is not None and not df.empty:
                # ì›ë³¸ íŒŒì¼ ì •ë³´ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€ (ì„ íƒì )
                df_copy = df.copy()
                dataframes.append(df_copy)
                logger.debug(f"  - {file_info['file_name']}: {len(df)}ê°œ í–‰ ì¶”ê°€")
        
        if not dataframes:
            logger.warning(f"âš ï¸ [{table_type}] í•©ì¹  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ëª¨ë“  DataFrame í•©ì¹˜ê¸°
        merged_df = pd.concat(dataframes, ignore_index=True)
        original_count = len(merged_df)
        logger.info(f"ğŸ“Š [{table_type}] í•©ì¹œ ë°ì´í„°: {original_count}ê°œ í–‰")
        
        # ì¤‘ë³µ ì œê±°
        # ëª¨ë“  ì»¬ëŸ¼ì´ ë™ì¼í•œ í–‰ì„ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
        deduplicated_df = merged_df.drop_duplicates(keep='first')
        removed_count = original_count - len(deduplicated_df)
        
        if removed_count > 0:
            logger.info(f"ğŸ—‘ï¸ [{table_type}] ì¤‘ë³µ ì œê±°: {removed_count}ê°œ í–‰ ì œê±°ë¨ ({original_count} â†’ {len(deduplicated_df)})")
        else:
            logger.info(f"âœ… [{table_type}] ì¤‘ë³µ ë°ì´í„° ì—†ìŒ")
        
        # ë°˜ëª… í•„í„°ë§ (TEST, ë©´ì ‘, ìì†Œì„œ, ìƒë‹´, ëŒ€ì… í¬í•¨ëœ ë°ì´í„° ì œê±°)
        before_filter_count = len(deduplicated_df)
        filtered_df = self._filter_by_class_name(deduplicated_df)
        filter_removed_count = before_filter_count - len(filtered_df)
        
        if filter_removed_count > 0:
            logger.info(f"ğŸ” [{table_type}] ë°˜ëª… í•„í„°ë§: {filter_removed_count}ê°œ í–‰ ì œê±°ë¨ (í•„í„° í‚¤ì›Œë“œ: {self.filter_keywords})")
        else:
            logger.info(f"âœ… [{table_type}] ë°˜ëª… í•„í„°ë§: ì œê±°ëœ ë°ì´í„° ì—†ìŒ")
        
        # ë‚ ì§œ í•„í„°ë§ (Notionì— ìˆëŠ” ë‚ ì§œ ë²”ìœ„ ì œì™¸)
        before_date_filter_count = len(filtered_df)
        date_filtered_df = await self._filter_by_notion_date_range(filtered_df, table_type)
        #date_filtered_df = filtered_df
        date_filter_removed_count = before_date_filter_count - len(date_filtered_df)
        
        if date_filter_removed_count > 0:
            logger.info(f"ğŸ“… [{table_type}] ë‚ ì§œ í•„í„°ë§: {date_filter_removed_count}ê°œ í–‰ ì œê±°ë¨ (Notion ë‚ ì§œ ë²”ìœ„ ì œì™¸)")
        else:
            logger.info(f"âœ… [{table_type}] ë‚ ì§œ í•„í„°ë§: ì œê±°ëœ ë°ì´í„° ì—†ìŒ")
        
        logger.info(f"âœ… [{table_type}] ì „ì²˜ë¦¬ ì™„ë£Œ: ìµœì¢… {len(date_filtered_df)}ê°œ í–‰ (ì›ë³¸: {original_count} â†’ ì¤‘ë³µì œê±°: {before_filter_count} â†’ ë°˜ëª…í•„í„°: {before_date_filter_count} â†’ ë‚ ì§œí•„í„°: {len(date_filtered_df)})")
        
        return date_filtered_df
    
    async def _filter_by_notion_date_range(self, df: pd.DataFrame, table_type: str) -> pd.DataFrame:
        """Notionì˜ ë‚ ì§œ ë²”ìœ„ì— í¬í•¨ëœ ë°ì´í„° ì œê±°
        
        Args:
            df: í•„í„°ë§í•  DataFrame
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
        
        Returns:
            ë‚ ì§œ ë²”ìœ„ ë°–ì˜ ë°ì´í„°ë§Œ ë‚¨ì€ DataFrame
        """
        if df.empty:
            return df
        
        if not self.notion:
            logger.warning("âš ï¸ NotionManagerê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë‚ ì§œ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return df
        
        # ë‚ ì§œ ì†ì„±ëª… ê²°ì •
        date_property = None
        if table_type in ["class", "student"]:
            date_property = "start_date"
        elif table_type == "discharge":
            date_property = "discharge_date"
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í…Œì´ë¸” íƒ€ì…: {table_type}, ë‚ ì§œ í•„í„°ë§ ê±´ë„ˆëœ€")
            return df
        
        # Notionì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¡°íšŒ
        date_range = await self.notion.get_date_range_from_table(table_type, date_property)
        
        if not date_range:
            logger.info(f"ğŸ“­ [{table_type}] Notionì— ë°ì´í„°ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
            return df
        
        first_date, last_date = date_range
        logger.info(f"ğŸ“… [{table_type}] Notion ë‚ ì§œ ë²”ìœ„: {first_date.date()} ~ {last_date.date()}")
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° (ë” ìœ ì—°í•˜ê²Œ)
        date_col = None
        for col in df.columns:
            col_str = str(col).strip()
            col_lower = col_str.lower()
            
            if date_property == "start_date":
                # ì…ì†Œì¼ì ê´€ë ¨ í‚¤ì›Œë“œ
                if any(keyword in col_str for keyword in ['ì…ì†Œì¼ì', 'ì…ì†Œì¼', 'ì…ì†Œ ë‚ ì§œ', 'ì‹œì‘ì¼', 'ì‹œì‘ ë‚ ì§œ']):
                    date_col = col
                    break
                elif 'start_date' in col_lower or 'startdate' in col_lower:
                    date_col = col
                    break
                elif 'ë‚ ì§œ' in col_str and any(keyword in col_str for keyword in ['ì…ì†Œ', 'ì‹œì‘']):
                    date_col = col
                    break
            elif date_property == "discharge_date":
                # í‡´ì†Œì¼ì ê´€ë ¨ í‚¤ì›Œë“œ
                if any(keyword in col_str for keyword in ['í‡´ì†Œì¼ì', 'í‡´ì†Œì¼', 'í‡´ì›ì¼ì', 'í‡´ì›ì¼', 'í‡´ì†Œ ë‚ ì§œ', 'í‡´ì› ë‚ ì§œ']):
                    date_col = col
                    break
                elif 'discharge_date' in col_lower or 'dischargedate' in col_lower:
                    date_col = col
                    break
                elif 'ë‚ ì§œ' in col_str and any(keyword in col_str for keyword in ['í‡´ì†Œ', 'í‡´ì›']):
                    date_col = col
                    break
        
        if not date_col:
            # ë””ë²„ê¹…: ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ëª… ì¶œë ¥
            available_cols = [str(col) for col in df.columns]
            logger.warning(f"âš ï¸ [{table_type}] ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‚ ì§œ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            logger.debug(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_cols}")
            logger.debug(f"   ì°¾ëŠ” ë‚ ì§œ ì†ì„±: {date_property}")
            return df
        
        # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
        try:
            df[date_col] = pd.to_datetime(df[date_col])
        except Exception as e:
            logger.error(f"âŒ ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return df
        
        # ë‚ ì§œ ë²”ìœ„ ë°–ì˜ ë°ì´í„°ë§Œ ë‚¨ê¸°ê¸° (ë²”ìœ„ ë‚´ ë°ì´í„° ì œê±°)
        # first_date <= ë‚ ì§œ <= last_date ë²”ìœ„ì˜ ë°ì´í„° ì œê±°
        before_count = len(df)
        filtered_df = df[(df[date_col] < first_date) | (df[date_col] > last_date)]
        removed_count = before_count - len(filtered_df)
        
        if removed_count > 0:
            logger.info(f"ğŸ—‘ï¸ [{table_type}] ë‚ ì§œ ë²”ìœ„ ë‚´ ë°ì´í„° {removed_count}ê°œ ì œê±°ë¨ ({first_date.date()} ~ {last_date.date()})")
        
        return filtered_df.reset_index(drop=True)
    
    def _filter_by_class_name(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°˜ëª…ì— í•„í„° í‚¤ì›Œë“œê°€ í¬í•¨ëœ í–‰ ì œê±°
        
        Args:
            df: ì „ì²˜ë¦¬í•  DataFrame
        
        Returns:
            í•„í„°ë§ëœ DataFrame
        """
        if df.empty:
            return df
        
        # ë°˜ëª… ì»¬ëŸ¼ ì°¾ê¸° (ìœ ì—°í•˜ê²Œ)
        class_name_col = None
        for col in df.columns:
            col_lower = str(col).lower()
            if 'ë°˜ëª…' in col_lower or 'class_name' in col_lower or 'ë°˜' in col_lower:
                class_name_col = col
                break
        
        if not class_name_col:
            logger.warning("âš ï¸ ë°˜ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return df
        
        # í•„í„°ë§: ë°˜ëª…ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ í–‰ ì œê±°
        def should_filter_row(class_name_value):
            if pd.isna(class_name_value):
                return False
            class_name_upper = str(class_name_value).upper()
            for keyword in self.filter_keywords:
                if keyword in class_name_upper:
                    return True
            return False
        
        filtered_df = df[~df[class_name_col].apply(should_filter_row)]
        
        return filtered_df.reset_index(drop=True)
    
    async def preprocess_all_folders(self) -> Dict[str, Optional[pd.DataFrame]]:
        """ëª¨ë“  í´ë”ì˜ íŒŒì¼ë“¤ì„ ì „ì²˜ë¦¬ (í•©ì¹˜ê¸° + ì¤‘ë³µ ì œê±° + ë‚ ì§œ í•„í„°ë§)
        
        Returns:
            Dict[str, Optional[pd.DataFrame]]: í´ë”ë³„ ì „ì²˜ë¦¬ëœ DataFrame
        """
        result = {}
        
        for table_type in ["class", "discharge", "student"]:
            result[table_type] = await self.preprocess_and_merge(table_type)
        
        return result
    
    def get_stored_files(self, table_type: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:
        """ì €ì¥ëœ íŒŒì¼ ì •ë³´ ì¡°íšŒ
        
        Args:
            table_type: íŠ¹ì • í…Œì´ë¸” íƒ€ì…ë§Œ ì¡°íšŒ (Noneì´ë©´ ì „ì²´)
        
        Returns:
            í´ë”ë³„ë¡œ ì €ì¥ëœ íŒŒì¼ ì •ë³´
        """
        if table_type:
            return {table_type: self.stored_files.get(table_type, [])}
        return self.stored_files.copy()
    
    def clear_stored_files(self, table_type: Optional[str] = None):
        """ì €ì¥ëœ íŒŒì¼ ì •ë³´ ì´ˆê¸°í™”
        
        Args:
            table_type: íŠ¹ì • í…Œì´ë¸” íƒ€ì…ë§Œ ì´ˆê¸°í™” (Noneì´ë©´ ì „ì²´)
        """
        if table_type:
            if table_type in self.stored_files:
                self.stored_files[table_type] = []
                logger.info(f"ğŸ”„ [{table_type}] í´ë”ì˜ ì €ì¥ëœ íŒŒì¼ ì •ë³´ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            for table_type in self.stored_files:
                self.stored_files[table_type] = []
            logger.info("ğŸ”„ ëª¨ë“  í´ë”ì˜ ì €ì¥ëœ íŒŒì¼ ì •ë³´ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def reset_processed_files(self):
        """ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ì´ˆê¸°í™” (ëª¨ë“  íŒŒì¼ì„ ë‹¤ì‹œ ì½ì„ ìˆ˜ ìˆë„ë¡)"""
        self.processed_files.clear()
        self.queued_files.clear()  # í ëª©ë¡ë„ í•¨ê»˜ ì´ˆê¸°í™”
        logger.info("ğŸ”„ ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ë° í ëª©ë¡ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def move_processed_files_to_imported(self, table_type: str) -> int:
        """ì²˜ë¦¬ëœ íŒŒì¼ë“¤ì„ imported í´ë”ë¡œ ì´ë™
        
        Args:
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
        
        Returns:
            ì´ë™ëœ íŒŒì¼ ìˆ˜
        """
        if table_type not in self.stored_files:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í…Œì´ë¸” íƒ€ì…: {table_type}")
            return 0
        
        file_list = self.stored_files[table_type]
        if not file_list:
            logger.warning(f"âš ï¸ [{table_type}] ì´ë™í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        # imported í´ë” ìƒì„±
        imported_dir = self.input_dir / "imported" / table_type
        imported_dir.mkdir(parents=True, exist_ok=True)
        
        moved_count = 0
        
        for file_info in file_list:
            try:
                file_path = Path(file_info["file_path"])
                file_key = file_info.get("file_key")
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                if not file_path.is_absolute():
                    file_path = Path.cwd() / file_path
                
                if not file_path.exists():
                    logger.warning(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                    # íŒŒì¼ì´ ì—†ì–´ë„ ì¶”ì  ëª©ë¡ì—ì„œ ì œê±°
                    if file_key:
                        self.queued_files.discard(file_key)
                        self.processed_files.add(file_key)
                    continue
                
                # imported í´ë”ë¡œ ì´ë™í•  íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_name = file_path.name
                name_parts = file_name.rsplit('.', 1)
                if len(name_parts) == 2:
                    new_file_name = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
                else:
                    new_file_name = f"{file_name}_{timestamp}"
                
                dest_path = imported_dir / new_file_name
                
                # íŒŒì¼ ì´ë™
                file_path.rename(dest_path)
                moved_count += 1
                logger.info(f"ğŸ“¦ [{table_type}] íŒŒì¼ ì´ë™: {file_path.name} â†’ {dest_path}")
                
                # íŒŒì¼ ì´ë™ ì„±ê³µ ì‹œ ì¶”ì  ëª©ë¡ ì—…ë°ì´íŠ¸
                if file_key:
                    self.queued_files.discard(file_key)  # í ëª©ë¡ì—ì„œ ì œê±°
                    self.processed_files.add(file_key)  # ì²˜ë¦¬ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€
                
            except Exception as e:
                logger.error(f"âŒ [{table_type}] íŒŒì¼ ì´ë™ ì‹¤íŒ¨: {file_info['file_name']}, ì˜¤ë¥˜: {e}")
        
        if moved_count > 0:
            logger.info(f"âœ… [{table_type}] {moved_count}ê°œ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì™„ë£Œ")
            # ì´ë™ëœ íŒŒì¼ì€ stored_filesì—ì„œ ì œê±°
            self.stored_files[table_type] = []
        
        return moved_count
    
    def move_specific_files_to_imported(self, table_type: str, file_infos: List[Dict[str, Any]]) -> int:
        """íŠ¹ì • íŒŒì¼ë“¤ë§Œ imported í´ë”ë¡œ ì´ë™
        
        Args:
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
            file_infos: ì´ë™í•  íŒŒì¼ ì •ë³´ ëª©ë¡
        
        Returns:
            ì´ë™ëœ íŒŒì¼ ìˆ˜
        """
        if table_type not in self.stored_files:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í…Œì´ë¸” íƒ€ì…: {table_type}")
            return 0
        
        if not file_infos:
            logger.warning(f"âš ï¸ [{table_type}] ì´ë™í•  íŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        # imported í´ë” ìƒì„±
        imported_dir = self.input_dir / "imported" / table_type
        imported_dir.mkdir(parents=True, exist_ok=True)
        
        moved_count = 0
        moved_file_keys = set()
        
        for file_info in file_infos:
            try:
                file_path = Path(file_info["file_path"])
                file_key = file_info.get("file_key")
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                if not file_path.is_absolute():
                    file_path = Path.cwd() / file_path
                
                if not file_path.exists():
                    logger.warning(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                    # íŒŒì¼ì´ ì—†ì–´ë„ ì¶”ì  ëª©ë¡ì—ì„œ ì œê±°
                    if file_key:
                        self.queued_files.discard(file_key)
                        self.processed_files.add(file_key)
                        moved_file_keys.add(file_key)
                    continue
                
                # imported í´ë”ë¡œ ì´ë™í•  íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_name = file_path.name
                name_parts = file_name.rsplit('.', 1)
                if len(name_parts) == 2:
                    new_file_name = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
                else:
                    new_file_name = f"{file_name}_{timestamp}"
                
                dest_path = imported_dir / new_file_name
                
                # íŒŒì¼ ì´ë™
                file_path.rename(dest_path)
                moved_count += 1
                logger.info(f"ğŸ“¦ [{table_type}] íŒŒì¼ ì´ë™: {file_path.name} â†’ {dest_path}")
                
                # íŒŒì¼ ì´ë™ ì„±ê³µ ì‹œ ì¶”ì  ëª©ë¡ ì—…ë°ì´íŠ¸
                if file_key:
                    self.queued_files.discard(file_key)  # í ëª©ë¡ì—ì„œ ì œê±°
                    self.processed_files.add(file_key)  # ì²˜ë¦¬ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€
                    moved_file_keys.add(file_key)
                
            except Exception as e:
                logger.error(f"âŒ [{table_type}] íŒŒì¼ ì´ë™ ì‹¤íŒ¨: {file_info.get('file_name', 'unknown')}, ì˜¤ë¥˜: {e}")
        
        # stored_filesì—ì„œ ì´ë™ëœ íŒŒì¼ë“¤ë§Œ ì œê±°
        if moved_file_keys:
            remaining_files = [
                f for f in self.stored_files[table_type]
                if f.get("file_key") not in moved_file_keys
            ]
            self.stored_files[table_type] = remaining_files
            logger.debug(f"ğŸ”„ [{table_type}] stored_filesì—ì„œ {len(moved_file_keys)}ê°œ íŒŒì¼ ì œê±°, {len(remaining_files)}ê°œ íŒŒì¼ ë‚¨ìŒ")
        
        if moved_count > 0:
            logger.info(f"âœ… [{table_type}] {moved_count}ê°œ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì™„ë£Œ")
        
        return moved_count

####

class ExcelImporter:
    def __init__(self, notion_manager):
        self.notion = notion_manager

    async def get_date_range_from_notion(self, table_type: str, date_property: str) -> Optional[datetime]:
        """ë…¸ì…˜ DBì—ì„œ ë§ˆì§€ë§‰ ë‚ ì§œ ì¡°íšŒ
        
        Args:
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
            date_property: ë‚ ì§œ ì†ì„±ëª… (start_date, discharge_date ë“±)
        
        Returns:
            ë§ˆì§€ë§‰ ë‚ ì§œ (datetime) ë˜ëŠ” None
        """
        try:
            db_id = self.notion.db_map.get(table_type.lower())
            if not db_id:
                logger.error(f"âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {table_type}")
                return None
            
            # ê°€ì¥ ìµœì‹  ë°ì´í„°ë§Œ ì¡°íšŒ
            newest = await self.notion.client.databases.query(
                database_id=db_id,
                sorts=[{"property": date_property, "direction": "descending"}],
                page_size=1
            )
            
            if newest.get('results'):
                date_value = self.notion._get_date(newest['results'][0], date_property)
                if date_value:
                    try:
                        if "T" in date_value:
                            return datetime.fromisoformat(date_value.split("T")[0])
                        else:
                            return datetime.fromisoformat(date_value)
                    except Exception as e:
                        logger.error(f"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                        return None
            
            return None
        except Exception as e:
            logger.error(f"âŒ ë…¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    
    def _convert_dataframe_row_to_notion_properties(self, row: pd.Series, table_type: str, df: pd.DataFrame) -> Dict[str, Any]:
        """DataFrame í–‰ì„ Notion ì†ì„± í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            row: DataFrameì˜ í•œ í–‰
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
            df: ì „ì²´ DataFrame (ì»¬ëŸ¼ ì •ë³´ í™•ì¸ìš©)
        
        Returns:
            Notion ì†ì„± ë”•ì…”ë„ˆë¦¬
        """
        properties = {}
        
        # í…Œì´ë¸” íƒ€ì…ë³„ ë§¤í•‘
        if table_type == "class":
            # class í…Œì´ë¸” ì†ì„± ë§¤í•‘
            if "í•™ìƒëª…" in df.columns or "student_name" in df.columns:
                col = "í•™ìƒëª…" if "í•™ìƒëª…" in df.columns else "student_name"
                student_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["student_name"] = {"title": [{"text": {"content": student_name}}]}
            
            if "ë‹´ë‹¹" in df.columns or "teacher_name" in df.columns:
                col = "ë‹´ë‹¹" if "ë‹´ë‹¹" in df.columns else "teacher_name"
                teacher_name = row[col]
                if pd.notna(teacher_name):
                    if isinstance(teacher_name, str):
                        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        if "," in teacher_name:
                            teacher_list = [t.strip() for t in teacher_name.split(",")]
                            properties["teacher_name"] = {"multi_select": [{"name": str(t)} for t in teacher_list]}
                        else:
                            properties["teacher_name"] = {"rich_text": [{"text": {"content": str(teacher_name)}}]}
                    elif isinstance(teacher_name, list):
                        properties["teacher_name"] = {"multi_select": [{"name": str(t)} for t in teacher_name]}
            
            if "ë°˜ëª…" in df.columns or "class_name" in df.columns:
                col = "ë°˜ëª…" if "ë°˜ëª…" in df.columns else "class_name"
                class_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["class_name"] = {"rich_text": [{"text": {"content": class_name}}]}
            
            if "ë¶€ëª¨HP" in df.columns or "parent_phone_number" in df.columns:
                col = "ë¶€ëª¨HP" if "ë¶€ëª¨HP" in df.columns else "parent_phone_number"
                phone = str(row[col]) if pd.notna(row[col]) else ""
                properties["parent_phone_number"] = {"rich_text": [{"text": {"content": phone}}]}
            
            if "ì‹œì‘ì¼" in df.columns or "start_date" in df.columns:
                col = "ì‹œì‘ì¼" if "ì‹œì‘ì¼" in df.columns else "start_date"
                date_value = row[col]
                if pd.notna(date_value):
                    try:
                        if isinstance(date_value, datetime):
                            date_obj = date_value
                        elif isinstance(date_value, str):
                            date_obj = pd.to_datetime(date_value)
                        else:
                            date_obj = pd.to_datetime(date_value)
                        properties["start_date"] = {"date": {"start": date_obj.strftime("%Y-%m-%d")}}
                    except:
                        pass
            
            if "í•™êµëª…" in df.columns or "school_name" in df.columns:
                col = "í•™êµëª…" if "í•™êµëª…" in df.columns else "school_name"
                school_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["school_name"] = {"rich_text": [{"text": {"content": school_name}}]}
            
            if "í•™ë…„" in df.columns or "grade" in df.columns:
                col = "í•™ë…„" if "í•™ë…„" in df.columns else "grade"
                grade = row[col]
                if pd.notna(grade):
                    try:
                        # "3í•™ë…„" í˜•ì‹ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                        if isinstance(grade, str):
                            grade_num = re.search(r'\d+', grade)
                            if grade_num:
                                properties["grade"] = {"number": int(grade_num.group())}
                        else:
                            properties["grade"] = {"number": int(grade)}
                    except:
                        pass
            
            # type -> type (íŠ¹ëª©, ë³¸ê´€ êµ¬ë¶„)
            if "type" in df.columns or "íƒ€ì…" in df.columns or "êµ¬ë¶„" in df.columns:
                col = None
                if "type" in df.columns:
                    col = "type"
                elif "íƒ€ì…" in df.columns:
                    col = "íƒ€ì…"
                elif "êµ¬ë¶„" in df.columns:
                    col = "êµ¬ë¶„"
                
                if col and pd.notna(row[col]):
                    type_value = str(row[col]).strip()
                    if type_value:
                        # rich_text íƒ€ì…ìœ¼ë¡œ ì²˜ë¦¬ (íŠ¹ëª©, ë³¸ê´€)
                        properties["type"] = {"rich_text": [{"text": {"content": type_value}}]}
        
        elif table_type == "discharge":
            # discharge í…Œì´ë¸” ì†ì„± ë§¤í•‘ (ì§€ì •ëœ ì»¬ëŸ¼ëª… ì‚¬ìš©)
            # ì‹œì‘ì¼ -> start_date
            if "ì‹œì‘ì¼" in df.columns or "start_date" in df.columns:
                col = "ì‹œì‘ì¼" if "ì‹œì‘ì¼" in df.columns else "start_date"
                date_value = row[col]
                if pd.notna(date_value):
                    try:
                        if isinstance(date_value, datetime):
                            date_obj = date_value
                        elif isinstance(date_value, str):
                            date_obj = pd.to_datetime(date_value)
                        else:
                            date_obj = pd.to_datetime(date_value)
                        properties["start_date"] = {"date": {"start": date_obj.strftime("%Y-%m-%d")}}
                    except:
                        pass
            
            # í•™ìƒëª… -> student_name
            if "í•™ìƒëª…" in df.columns or "student_name" in df.columns:
                col = "í•™ìƒëª…" if "í•™ìƒëª…" in df.columns else "student_name"
                student_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["student_name"] = {"title": [{"text": {"content": student_name}}]}
            
            # ë¶€ëª¨HP -> parent_phone_number
            if "ë¶€ëª¨HP" in df.columns or "parent_phone_number" in df.columns:
                col = "ë¶€ëª¨HP" if "ë¶€ëª¨HP" in df.columns else "parent_phone_number"
                phone = str(row[col]) if pd.notna(row[col]) else ""
                properties["parent_phone_number"] = {"rich_text": [{"text": {"content": phone}}]}
            
            # ë°˜ëª… -> class_name
            if "ë°˜ëª…" in df.columns or "class_name" in df.columns:
                col = "ë°˜ëª…" if "ë°˜ëª…" in df.columns else "class_name"
                class_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["class_name"] = {"rich_text": [{"text": {"content": class_name}}]}
            
            # ë‹´ë‹¹ -> teacher_name
            if "ë‹´ë‹¹" in df.columns or "teacher_name" in df.columns:
                col = "ë‹´ë‹¹" if "ë‹´ë‹¹" in df.columns else "teacher_name"
                teacher_name = row[col]
                if pd.notna(teacher_name):
                    if isinstance(teacher_name, str):
                        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        if "," in teacher_name:
                            teacher_list = [t.strip() for t in teacher_name.split(",")]
                            properties["teacher_name"] = {"multi_select": [{"name": str(t)} for t in teacher_list]}
                        else:
                            properties["teacher_name"] = {"rich_text": [{"text": {"content": str(teacher_name)}}]}
                    elif isinstance(teacher_name, list):
                        properties["teacher_name"] = {"multi_select": [{"name": str(t)} for t in teacher_name]}
            
            # í‡´ì›ì‚¬ìœ  -> discharging_reason
            if "í‡´ì›ì‚¬ìœ " in df.columns or "discharging_reason" in df.columns:
                col = "í‡´ì›ì‚¬ìœ " if "í‡´ì›ì‚¬ìœ " in df.columns else "discharging_reason"
                reason = str(row[col]) if pd.notna(row[col]) else ""
                properties["discharging_reason"] = {"rich_text": [{"text": {"content": reason}}]}
            
            # í•™êµëª… -> school_name
            if "í•™êµëª…" in df.columns or "school_name" in df.columns:
                col = "í•™êµëª…" if "í•™êµëª…" in df.columns else "school_name"
                school_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["school_name"] = {"rich_text": [{"text": {"content": school_name}}]}
            
            # í•™ë…„ -> grade
            if "í•™ë…„" in df.columns or "grade" in df.columns:
                col = "í•™ë…„" if "í•™ë…„" in df.columns else "grade"
                grade = row[col]
                if pd.notna(grade):
                    try:
                        # "3í•™ë…„" í˜•ì‹ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                        if isinstance(grade, str):
                            grade_num = re.search(r'\d+', grade)
                            if grade_num:
                                properties["grade"] = {"number": int(grade_num.group())}
                        else:
                            properties["grade"] = {"number": int(grade)}
                    except:
                        pass
            
            # í‡´ì›ì¼ì -> discharge_date
            if "í‡´ì›ì¼ì" in df.columns or "discharge_date" in df.columns:
                col = "í‡´ì›ì¼ì" if "í‡´ì›ì¼ì" in df.columns else "discharge_date"
                date_value = row[col]
                if pd.notna(date_value):
                    try:
                        if isinstance(date_value, datetime):
                            date_obj = date_value
                        elif isinstance(date_value, str):
                            date_obj = pd.to_datetime(date_value)
                        else:
                            date_obj = pd.to_datetime(date_value)
                        properties["discharge_date"] = {"date": {"start": date_obj.strftime("%Y-%m-%d")}}
                    except:
                        pass
            
            # type -> type (íŠ¹ëª©, ë³¸ê´€ êµ¬ë¶„)
            if "type" in df.columns or "íƒ€ì…" in df.columns or "êµ¬ë¶„" in df.columns:
                col = None
                if "type" in df.columns:
                    col = "type"
                elif "íƒ€ì…" in df.columns:
                    col = "íƒ€ì…"
                elif "êµ¬ë¶„" in df.columns:
                    col = "êµ¬ë¶„"
                
                if col and pd.notna(row[col]):
                    type_value = str(row[col]).strip()
                    if type_value:
                        # rich_text íƒ€ì…ìœ¼ë¡œ ì²˜ë¦¬ (íŠ¹ëª©, ë³¸ê´€)
                        properties["type"] = {"rich_text": [{"text": {"content": type_value}}]}
        
        elif table_type == "student":
            # student í…Œì´ë¸” ì†ì„± ë§¤í•‘ (í•„ìš”í•œ ì†ì„± ì¶”ê°€)
            if "í•™ìƒëª…" in df.columns or "student_name" in df.columns:
                col = "í•™ìƒëª…" if "í•™ìƒëª…" in df.columns else "student_name"
                student_name = str(row[col]) if pd.notna(row[col]) else ""
                properties["student_name"] = {"title": [{"text": {"content": student_name}}]}
            
            # student í…Œì´ë¸”ì˜ ë‹¤ë¥¸ ì†ì„±ë“¤ë„ í•„ìš”ì— ë”°ë¼ ì¶”ê°€
        
        return properties
    
    async def add_preprocessed_data_to_notion(self, df: pd.DataFrame, table_type: str) -> int:
        """ì „ì²˜ë¦¬ëœ DataFrameì„ Notion DBì— ì¶”ê°€
        
        Args:
            df: ì „ì²˜ë¦¬ëœ DataFrame
            table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
        
        Returns:
            ì¶”ê°€ëœ í˜ì´ì§€ ìˆ˜
        """
        if df.empty:
            logger.warning(f"âš ï¸ [{table_type}] ì¶”ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        db_id = self.notion.db_map.get(table_type.lower())
        if not db_id:
            logger.error(f"âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {table_type}")
            return 0
        
        logger.info(f"ğŸ“¤ [{table_type}] Notion DBì— ë°ì´í„° ì¶”ê°€ ì‹œì‘: {len(df)}ê°œ í–‰")
        
        added_count = 0
        failed_count = 0
        
        for idx, row in df.iterrows():
            try:
                # DataFrame í–‰ì„ Notion ì†ì„±ìœ¼ë¡œ ë³€í™˜
                properties = self._convert_dataframe_row_to_notion_properties(row, table_type, df)
                
                if not properties:
                    logger.warning(f"âš ï¸ [{table_type}] í–‰ {idx}: ë³€í™˜ëœ ì†ì„±ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                # Notionì— ì¶”ê°€
                await self.notion.client.pages.create(
                    parent={"database_id": db_id},
                    properties=properties
                )
                
                added_count += 1
                if added_count % 10 == 0:
                    logger.info(f"ğŸ“ [{table_type}] ì§„í–‰ ì¤‘: {added_count}/{len(df)}ê°œ ì¶”ê°€ë¨")
                
                # API ì œí•œ ê³ ë ¤ (ì´ˆë‹¹ 3íšŒ)
                await asyncio.sleep(0.35)
                
            except Exception as e:
                failed_count += 1
                logger.error(f"âŒ [{table_type}] í–‰ {idx} ì¶”ê°€ ì‹¤íŒ¨: {e}")
        
        logger.info(f"âœ… [{table_type}] Notion DB ì¶”ê°€ ì™„ë£Œ: ì„±ê³µ {added_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
        
        return added_count


    


####

class EnhancedDischargeReportGenerator:
    """ì°¨íŠ¸ í¬í•¨ ì›”ë³„ ì…í‡´ì†Œ í˜„í™© ìƒì„±ê¸°"""
    
    def __init__(self, notion_manager):
        self.notion = notion_manager
    
    async def generate_monthly_report(self, query_results,
                                      teacher_name: str,
                                      year: Optional[int] = None,
                                      month: Optional[int] = None
                                      ) -> Dict:
        """
        ì›”ë³„ ì…í‡´ì†Œ í˜„í™© + 12ê°œì›” ì¶”ì´ ë°ì´í„° ìƒì„±
        
        Returns:
            {
                "current_month": {...},     # í•´ë‹¹ ì›” ìƒì„¸
                "yearly_trend": {...},       # 12ê°œì›” ì¶”ì´
                "detailed_list": [...]       # í•™ìƒë³„ ìƒì„¸ ëª…ë‹¨
            }
        """
        # ë…„ì›”ì´ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
        if year is None:
            year = datetime.now().year
        if month is None:
            month = datetime.now().month
        
        logger.info(f"ğŸ“Š {teacher_name} {year}ë…„ {month}ì›” ì…í‡´ì†Œ í˜„í™© ìƒì„±")
        
        # 1. í•´ë‹¹ ì›” ë°ì´í„°
        current_data = await self._get_current_month_data(
            query_results, year, month
        )
        
        # 2. 12ê°œì›” ì¶”ì´ ë°ì´í„° (ê³¼ê±° 11ê°œì›” + í˜„ì¬ì›”)
        yearly_trend = await self._get_yearly_trend(
            query_results, teacher_name, year, month
        )
        
        # 3. í•™ìƒë³„ ìƒì„¸ ëª…ë‹¨ (ì…ì†Œì¼, í‡´ì†Œì¼ í¬í•¨)
        detailed_list = await self._get_detailed_student_list(
            query_results
        )
        
        return {
            "teacher_name": teacher_name,
            "year": year,
            "month": month,
            "current_month": current_data,
            "yearly_trend": yearly_trend,
            "detailed_list": detailed_list
        }

    async def _get_current_month_data(self, query_results,
                                     year: int, 
                                     month: int) -> Dict:
        """í•´ë‹¹ ì›” ì…í‡´ì†Œ ë°ì´í„°"""

        # ì…ì†Œ ë°ì´í„° (class í…Œì´ë¸”)
        enrollments = await self.year_month_enrollment(
            query_results, year, month
        )
        
        # í‡´ì†Œ ë°ì´í„° (discharge í…Œì´ë¸”)
        discharges = await self.year_month_discharge(
            query_results, year, month
        )
        
        return {
            "enrollments": len(enrollments),
            "discharges": len(discharges),
            "net_change": len(enrollments) - len(discharges),
            "enrollment_list": enrollments,
            "discharge_list": discharges
        }
       
    async def _get_yearly_trend(self, query_results,
                                teacher_name: str, 
                                year: int, 
                                month: int) -> Dict:
        """ê°€ìš© ë°ì´í„° ê°œì›” ìˆ˜ì— ë§ì¶˜ ì›”ë³„ ì¶”ì´ ë°ì´í„°"""
        trend_data: List[Dict[str, Any]] = []

        # 1) ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ì›” ìˆ˜ì§‘ (class: start_date, discharge: discharge_date)
        months_set: set = set()

        def _add_month(val):
            if not val:
                return
            if isinstance(val, list):
                for v in val:
                    _add_month(v)
                return
            try:
                d = datetime.fromisoformat(str(val).split("T")[0])
                months_set.add((d.year, d.month))
            except Exception:
                return

        if isinstance(query_results, dict):
            normalized = {k.lower(): v for k, v in query_results.items()}
            for item in normalized.get("class", []):
                v = item.get("start_date") or item.get("start") or item.get("ì…ì†Œì¼") or item.get("startDate")
                _add_month(v)
            for item in normalized.get("discharge", []):
                v = item.get("discharge_date") or item.get("discharge") or item.get("í‡´ì†Œì¼") or item.get("dischargeDate")
                _add_month(v)

        # 2) ì‚¬ìš©í•  ì›” ëª©ë¡ ê²°ì •
        if months_set:
            month_targets = sorted(months_set)  # (year, month) ì˜¤ë¦„ì°¨ìˆœ
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ì²˜ëŸ¼ ìµœê·¼ 12ê°œì›”ì„ ì‚¬ìš©
            month_targets = []
            for i in range(11, -1, -1):
                target_date = datetime(year, month, 1) - timedelta(days=i*30)
                month_targets.append((target_date.year, target_date.month))

        # 3) ì›”ë³„ ì…ì†Œ/í‡´ì†Œ ì§‘ê³„
        for target_year, target_month in month_targets:
            start_date, end_date = self._get_month_range(target_year, target_month)

            enrollments = await self.year_month_enrollment(
                query_results, target_year, target_month
            )
            discharges = await self.year_month_discharge(
                query_results, target_year, target_month
            )

            logger.debug(f"[Trend] {target_year}-{target_month:02d} enrollments={len(enrollments)} discharges={len(discharges)}")

            trend_data.append({
                "year": target_year,
                "month": target_month,
                "month_label": f"{target_year}ë…„ {target_month}ì›”",
                "enrollments": len(enrollments),
                "discharges": len(discharges),
                "net_change": len(enrollments) - len(discharges)
            })

        # 4) ì°¨íŠ¸ íƒ€ì… ê²°ì •: ë°ì´í„°ê°€ í•œ ê°œì›”ë¿ì´ë©´ ë§‰ëŒ€í˜•
        chart_type = "bar" if len(trend_data) == 1 else "line"

        return {
            "monthly_data": trend_data,
            "chart_type": chart_type
        }
    
    async def _get_detailed_student_list(self, query_results
                                        ) -> List[Dict]:
        """í•™ìƒë³„ ìƒì„¸ ëª…ë‹¨ (ì…ì†Œì¼, í‡´ì†Œì¼ í¬í•¨)"""       
        detailed_list = []
        
        # 1. ì…ì†Œ í•™ìƒ (class í…Œì´ë¸” - í‡´ì†Œì¼ ì—†ìŒ)
        enrollments = query_results.get("class", [])

        for student in enrollments:
            # enrollments now use internal English keys; map to output Korean keys
            start_val = student.get("start_date")
            detailed_list.append({
                "í•™ìƒëª…": student.get("student_name"),
                "í•™ë…„": f"{student.get('grade')}í•™ë…„" if isinstance(student.get('grade'), int) else student.get('grade'),
                "ë°˜": student.get("class_name"),
                "ì…ì†Œì¼ì": start_val,
                "í‡´ì†Œì¼ì": None,
                "ì¬ì›ìƒíƒœ": "ì¬ì›ì¤‘",
                "ì¬ì›ê¸°ê°„": self._calculate_days_from(start_val),
                "í‡´ì›ì‚¬ìœ ": None,
                "í•™ë¶€ëª¨ì „í™”": student.get("parent_phone_number")
            })
        
        # 2. í‡´ì†Œ í•™ìƒ (discharge í…Œì´ë¸” - ì…ì†Œì¼ + í‡´ì†Œì¼ ìˆìŒ)
        discharges = query_results.get("discharge", [])

        for student in discharges:
            start_val = student.get("start_date")
            end_val = student.get("discharge_date")
            detailed_list.append({
                "í•™ìƒëª…": student.get("student_name"),
                "í•™ë…„": f"{student.get('grade')}í•™ë…„" if isinstance(student.get('grade'), int) else student.get('grade'),
                "ë°˜": ", ".join(student.get("class_name", [])) if isinstance(student.get("class_name"), list) else student.get("class_name", ""),
                "ì…ì†Œì¼ì": start_val,
                "í‡´ì†Œì¼ì": end_val,
                "ì¬ì›ìƒíƒœ": "í‡´ì›",
                "ì¬ì›ê¸°ê°„": self._calculate_duration(
                    start_val, 
                    end_val
                ),
                "í‡´ì›ì‚¬ìœ ": student.get("discharging_reason"),
                "í•™ë¶€ëª¨ì „í™”": student.get("parent_phone_number")
        })
        
        # í‡´ì†Œì¼ì ê¸°ì¤€ ì •ë ¬ (í‡´ì†Œì¼ìê°€ ì—†ìœ¼ë©´ ì…ì†Œì¼ì ì‚¬ìš©)
        detailed_list.sort(
            key=lambda x: x.get("í‡´ì†Œì¼ì") or x.get("ì…ì†Œì¼ì") or "9999-99-99"
        )
        
        return detailed_list
    
   
            
    async def year_month_enrollment(self, query_results: Dict, year: int, month: int) -> List[Dict]:
        """Compatibility wrapper for requested name `year_month_enrollment`."""
        # Normalize keys and pull class list
        if isinstance(query_results, dict):
            normalized = {k.lower(): v for k, v in query_results.items()}
        else:
            return []

        class_list = normalized.get("class", [])
        start_range, end_range = self._get_month_range(year, month)

        filtered: List[Dict] = []
        for item in class_list:
            # possible date keys
            val = item.get("start_date") or item.get("start") or item.get("ì…ì†Œì¼") or item.get("startDate")
            # support nested Notion-like dicts
            if isinstance(val, dict):
                val = val.get("date") or val.get("start") or val.get("start_date")
                if isinstance(val, dict):
                    val = val.get("start")
            if not val:
                continue
            try:
                d = datetime.fromisoformat(str(val).split("T")[0])
            except Exception:
                continue
            if start_range.date() <= d.date() <= end_range.date():
                filtered.append(item)
        return filtered

    async def year_month_discharge(self, query_results: Dict, year: int, month: int) -> List[Dict]:
        """Compatibility wrapper for requested name `year_month_discharge`."""
        # Normalize keys and pull discharge list
        if isinstance(query_results, dict):
            normalized = {k.lower(): v for k, v in query_results.items()}
        else:
            return []

        discharge_list = normalized.get("discharge", [])
        start_range, end_range = self._get_month_range(year, month)

        filtered: List[Dict] = []
        for item in discharge_list:
            val = item.get("discharge_date") or item.get("discharge") or item.get("í‡´ì†Œì¼") or item.get("dischargeDate")
            if isinstance(val, dict):
                val = val.get("date") or val.get("start") or val.get("discharge_date")
                if isinstance(val, dict):
                    val = val.get("start")
            if not val:
                continue
            try:
                d = datetime.fromisoformat(str(val).split("T")[0])
            except Exception:
                continue
            if start_range.date() <= d.date() <= end_range.date():
                filtered.append(item)
        return filtered

    
    def _get_month_range(self, year: int, month: int) -> Tuple[datetime, datetime]:
        """í•´ë‹¹ ì›”ì˜ ì‹œì‘ì¼/ì¢…ë£Œì¼"""
        start_date = datetime(year, month, 1)
        if month == 12:
            end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
        else:
            end_date = datetime(year, month + 1, 1) - timedelta(days=1)
        return start_date, end_date
    
    def _calculate_duration(self, start_str: str, end_str: str) -> str:
        """ì¬ì› ê¸°ê°„ ê³„ì‚°"""
        try:
            start = datetime.fromisoformat(start_str.split("T")[0])
            end = datetime.fromisoformat(end_str.split("T")[0])
            days = (end - start).days
            
            if days < 30:
                return f"{days}ì¼"
            else:
                months = days // 30
                remaining = days % 30
                if remaining > 0:
                    return f"{months}ê°œì›” {remaining}ì¼"
                return f"{months}ê°œì›”"
        except:
            return "-"
        
    def _calculate_days_from(self, start_str: str) -> str:
        """ì…ì†Œì¼ë¶€í„° í˜„ì¬ê¹Œì§€"""
        try:
            start = datetime.fromisoformat(start_str.split("T")[0])
            days = (datetime.now() - start).days
            
            if days < 30:
                return f"{days}ì¼"
            else:
                months = days // 30
                remaining = days % 30
                return f"{months}ê°œì›” {remaining}ì¼"
        except:
            return "-"
        
    
    def create_excel_with_chart(self, report_data: Dict, 
                                filename: str) -> Path:
        """ì°¨íŠ¸ í¬í•¨ Excel ìƒì„±"""
        logger.info("ğŸ“Š ì°¨íŠ¸ í¬í•¨ Excel ìƒì„± ì¤‘...")
        
        wb = openpyxl.Workbook()
        wb.remove(wb.active)
        
        # ===== ì‹œíŠ¸ 1: ì›”ë³„ ì¶”ì´ (ì°¨íŠ¸ í¬í•¨) =====
        ws_trend = wb.create_sheet("ì›”ë³„ ì¶”ì´")
        self._create_trend_sheet_with_chart(ws_trend, report_data)

        # ===== ì‹œíŠ¸ 2: ì›”ë³„ ìš”ì•½ =====
        ws_summary = wb.create_sheet("ì›”ë³„ ìš”ì•½")
        self._create_summary_sheet(ws_summary, report_data)
        
        # ===== ì‹œíŠ¸ 3: ê³¼ëª©ë³„ ì…í‡´ì†Œ ì¶”ì´ ì‹œíŠ¸ + ì°¨íŠ¸ =====
        ws_class_trend = wb.create_sheet("ê³¼ëª©ë³„ ì…í‡´ì†Œ ì¶”ì´")
        self._create_class_trend_sheet_with_chart(ws_class_trend, report_data)

        # ===== ì‹œíŠ¸ 4: ê³¼ëª©ë³„ í‡´ì†Œ ì‚¬ìœ  ìˆœìœ„ ìš”ì•½ ì‹œíŠ¸ =====
        ws_class_summary = wb.create_sheet("ê³¼ëª©ë³„ í‡´ì†Œ ì‚¬ìœ  ìˆœìœ„ ìš”ì•½")
        self._create_class_summary_sheet(ws_class_summary, report_data)
        
        # ===== ì‹œíŠ¸ 5: í•™ìƒë³„ ìƒì„¸ ëª…ë‹¨ =====
        ws_detail = wb.create_sheet("í•™ìƒ ìƒì„¸")
        self._create_detail_sheet(ws_detail, report_data)

        
        
        # ì €ì¥
        output_path = Path("temp") / f"{filename}.xlsx"
        wb.save(output_path)
        
        logger.info(f"âœ… ì°¨íŠ¸ í¬í•¨ Excel ìƒì„± ì™„ë£Œ: {output_path.name}")
        return output_path
    
    def _create_trend_sheet_with_chart(self, ws, report_data: Dict):
        """ì›”ë³„ ì¶”ì´ ì‹œíŠ¸ + ì°¨íŠ¸ (ë°ì´í„° ê°œì›”ìˆ˜ ê¸°ë°˜)"""
        trend_info = report_data.get("yearly_trend", {})
        trend_data = trend_info.get("monthly_data", [])
        chart_type = trend_info.get("chart_type", "line")
        month_count = len(trend_data)
        
        # ì œëª©
        ws.merge_cells('A1:G1')
        title = ws['A1']
        title.value = f"ğŸ“ˆ {report_data['teacher_name']} - {month_count}ê°œì›” ì…í‡´ì†Œ ì¶”ì´"
        title.font = Font(size=16, bold=True, color="FFFFFF")
        title.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        title.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[1].height = 30
        
        # í—¤ë”
        headers = ["ì›”", "ì…ì†Œ", "í‡´ì†Œ", "ìˆœì¦ê°"]
        header_row = 3
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=header_row, column=col)
            cell.value = header
            cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal="center")
        
        # ë°ì´í„°
        for row_idx, data in enumerate(trend_data, header_row + 1):
            ws.cell(row=row_idx, column=1).value = f"{data['year']}.{data['month']:02d}"
            ws.cell(row=row_idx, column=2).value = data['enrollments']
            ws.cell(row=row_idx, column=3).value = data['discharges']
            ws.cell(row=row_idx, column=4).value = data['net_change']
            
            # ìˆœì¦ê° ìƒ‰ìƒ
            net_cell = ws.cell(row=row_idx, column=4)
            if data['net_change'] > 0:
                net_cell.font = Font(color="00B050", bold=True)
            elif data['net_change'] < 0:
                net_cell.font = Font(color="FF0000", bold=True)
            
            # ìŠ¤íŠ¸ë¼ì´í”„
            if row_idx % 2 == 0:
                for col in range(1, 5):
                    ws.cell(row=row_idx, column=col).fill = PatternFill(
                        start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                    )
        
        # ì—´ ë„ˆë¹„
        ws.column_dimensions['A'].width = 12
        ws.column_dimensions['B'].width = 10
        ws.column_dimensions['C'].width = 10
        ws.column_dimensions['D'].width = 10
        
        # ===== ì°¨íŠ¸ ìƒì„± =====
        # ë°ì´í„° ë²”ìœ„ (ì›”, ì…ì†Œ, í‡´ì†Œ)
        data_ref = Reference(ws, min_col=2, min_row=header_row, 
                             max_row=header_row + len(trend_data), max_col=3)
        cats_ref = Reference(ws, min_col=1, min_row=header_row + 1, 
                             max_row=header_row + len(trend_data))

        if chart_type == "bar":
            # ë°ì´í„°ê°€ í•œ ê°œì›”ë¿ì´ë©´ ë§‰ëŒ€í˜•ìœ¼ë¡œ í‘œí˜„
            bar_chart_main = BarChart()
            bar_chart_main.type = "col"
            bar_chart_main.title = "ì›”ë³„ ì…í‡´ì†Œ"
            bar_chart_main.y_axis.title = "ì¸ì› (ëª…)"
            bar_chart_main.x_axis.title = "ì›”"
            bar_chart_main.height = 12
            bar_chart_main.width = 24
            bar_chart_main.add_data(data_ref, titles_from_data=True)
            bar_chart_main.set_categories(cats_ref)
            bar_chart_main.dataLabels = DataLabelList()
            bar_chart_main.dataLabels.showVal = True
            ws.add_chart(bar_chart_main, f"F3")
        else:
            # ê¸°ë³¸: êº¾ì€ì„  ì°¨íŠ¸ (ì…ì†Œ/í‡´ì†Œ)
            line_chart = LineChart()
            line_chart.title = "ì›”ë³„ ì…í‡´ì†Œ ì¶”ì´"
            line_chart.style = 13
            line_chart.y_axis.title = "ì¸ì› (ëª…)"
            line_chart.x_axis.title = "ì›”"
            line_chart.height = 12
            line_chart.width = 24
            
            line_chart.add_data(data_ref, titles_from_data=True)
            line_chart.set_categories(cats_ref)
            try:
                line_chart.series[0].graphicalProperties.line.solidFill = "00B050"
                line_chart.series[1].graphicalProperties.line.solidFill = "FF0000"
            except Exception:
                pass
            
            line_chart.dataLabels = DataLabelList()
            line_chart.dataLabels.showVal = True
            ws.add_chart(line_chart, f"F3")
        
        # ë§‰ëŒ€ ì°¨íŠ¸ (ìˆœì¦ê°)
        bar_chart = BarChart()
        bar_chart.type = "col"
        bar_chart.title = "ì›”ë³„ ìˆœì¦ê°"
        bar_chart.y_axis.title = "ìˆœì¦ê° (ëª…)"
        bar_chart.x_axis.title = "ì›”"
        bar_chart.height = 12
        bar_chart.width = 24
        
        # ìˆœì¦ê° ë°ì´í„°
        data = Reference(ws, min_col=4, min_row=header_row, 
                        max_row=header_row + len(trend_data))
        cats = Reference(ws, min_col=1, min_row=header_row + 1, 
                        max_row=header_row + len(trend_data))
        
        bar_chart.add_data(data, titles_from_data=True)
        bar_chart.set_categories(cats)
        
        # ì°¨íŠ¸ ì‚½ì…
        ws.add_chart(bar_chart, f"F23")
    
    def _create_class_trend_sheet_with_chart(self, ws, report_data: Dict):
        """ê³¼ëª©ë³„ ì…í‡´ì†Œ ì¶”ì´ ì‹œíŠ¸ + ì°¨íŠ¸"""
        detailed_list = report_data.get("detailed_list", [])
        
        # ê³¼ëª©ë³„ ì…ì†Œ/í‡´ì†Œ ì§‘ê³„
        subject_enrollments = Counter()
        subject_discharges = Counter()
        
        for student in detailed_list:
            subject = student.get("ë°˜", "ê¸°íƒ€")
            # ë°˜ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(subject, list):
                subjects = subject
            elif isinstance(subject, str) and "," in subject:
                subjects = [s.strip() for s in subject.split(",")]
            else:
                subjects = [subject] if subject else ["ê¸°íƒ€"]
            
            for subj in subjects:
                if student.get("ì¬ì›ìƒíƒœ") == "ì¬ì›ì¤‘":
                    subject_enrollments[subj] += 1
                elif student.get("ì¬ì›ìƒíƒœ") == "í‡´ì›":
                    subject_discharges[subj] += 1
        
        # ëª¨ë“  ê³¼ëª© ìˆ˜ì§‘ ë° ì •ë ¬
        all_subjects = set(subject_enrollments.keys()) | set(subject_discharges.keys())
        subject_data = []
        for subject in sorted(all_subjects):
            enrollments = subject_enrollments.get(subject, 0)
            discharges = subject_discharges.get(subject, 0)
            net_change = enrollments - discharges
            subject_data.append({
                "subject": subject,
                "enrollments": enrollments,
                "discharges": discharges,
                "net_change": net_change
            })
        
        # ì œëª©
        ws.merge_cells('A1:G1')
        title = ws['A1']
        title.value = f"ğŸ“š {report_data['teacher_name']} - ê³¼ëª©ë³„ ì…í‡´ì†Œ ì¶”ì´"
        title.font = Font(size=16, bold=True, color="FFFFFF")
        title.fill = PatternFill(start_color="7030A0", end_color="7030A0", fill_type="solid")
        title.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[1].height = 30
        
        # í—¤ë”
        headers = ["ê³¼ëª©", "ì…ì†Œ", "í‡´ì†Œ", "ìˆœì¦ê°"]
        header_row = 3
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=header_row, column=col)
            cell.value = header
            cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            cell.font = Font(color="FFFFFF", bold=True)
            cell.alignment = Alignment(horizontal="center")
        
        # ë°ì´í„°
        for row_idx, data in enumerate(subject_data, header_row + 1):
            ws.cell(row=row_idx, column=1).value = data['subject']
            ws.cell(row=row_idx, column=2).value = data['enrollments']
            ws.cell(row=row_idx, column=3).value = data['discharges']
            ws.cell(row=row_idx, column=4).value = data['net_change']
            
            # ìˆœì¦ê° ìƒ‰ìƒ
            net_cell = ws.cell(row=row_idx, column=4)
            if data['net_change'] > 0:
                net_cell.font = Font(color="00B050", bold=True)
            elif data['net_change'] < 0:
                net_cell.font = Font(color="FF0000", bold=True)
            
            # ìŠ¤íŠ¸ë¼ì´í”„
            if row_idx % 2 == 0:
                for col in range(1, 5):
                    ws.cell(row=row_idx, column=col).fill = PatternFill(
                        start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                    )
        
        # ì—´ ë„ˆë¹„
        ws.column_dimensions['A'].width = 20  # ê³¼ëª©ëª…ì€ ë” ë„“ê²Œ
        ws.column_dimensions['B'].width = 10
        ws.column_dimensions['C'].width = 10
        ws.column_dimensions['D'].width = 10
        
        # ===== ì°¨íŠ¸ ìƒì„± =====
        # ë§‰ëŒ€ ì°¨íŠ¸ (ì…ì†Œ/í‡´ì†Œ)
        bar_chart_enroll = BarChart()
        bar_chart_enroll.type = "col"
        bar_chart_enroll.title = "ê³¼ëª©ë³„ ì…í‡´ì†Œ ì¶”ì´"
        bar_chart_enroll.style = 13
        bar_chart_enroll.y_axis.title = "ì¸ì› (ëª…)"
        bar_chart_enroll.x_axis.title = "ê³¼ëª©"
        bar_chart_enroll.height = 12
        bar_chart_enroll.width = 24
        
        # ë°ì´í„° ë²”ìœ„
        data = Reference(ws, min_col=2, min_row=header_row, 
                        max_row=header_row + len(subject_data), max_col=3)
        cats = Reference(ws, min_col=1, min_row=header_row + 1, 
                        max_row=header_row + len(subject_data))
        
        bar_chart_enroll.add_data(data, titles_from_data=True)
        bar_chart_enroll.set_categories(cats)
        # ìƒ‰ìƒ ì§€ì •: series[0]=ì…ì†Œ(ì´ˆë¡), series[1]=í‡´ì†Œ(ë¶‰ì€)
        try:
            bar_chart_enroll.series[0].graphicalProperties.solidFill = "00B050"
            bar_chart_enroll.series[1].graphicalProperties.solidFill = "FF0000"
        except Exception:
            pass
        
        # ë°ì´í„° ë ˆì´ë¸” í‘œì‹œ
        bar_chart_enroll.dataLabels = DataLabelList()
        bar_chart_enroll.dataLabels.showVal = True
        
        # ì°¨íŠ¸ ì‚½ì… ìœ„ì¹˜
        ws.add_chart(bar_chart_enroll, f"F3")
        
        # ë§‰ëŒ€ ì°¨íŠ¸ (ìˆœì¦ê°)
        bar_chart = BarChart()
        bar_chart.type = "col"
        bar_chart.title = "ê³¼ëª©ë³„ ìˆœì¦ê°"
        bar_chart.y_axis.title = "ìˆœì¦ê° (ëª…)"
        bar_chart.x_axis.title = "ê³¼ëª©"
        bar_chart.height = 12
        bar_chart.width = 24
        
        # ìˆœì¦ê° ë°ì´í„°
        data = Reference(ws, min_col=4, min_row=header_row, 
                        max_row=header_row + len(subject_data))
        cats = Reference(ws, min_col=1, min_row=header_row + 1, 
                        max_row=header_row + len(subject_data))
        
        bar_chart.add_data(data, titles_from_data=True)
        bar_chart.set_categories(cats)
        
        # ì°¨íŠ¸ ì‚½ì…
        ws.add_chart(bar_chart, f"F23")
    
    def _create_summary_sheet(self, ws, report_data: Dict):
        """ëª¨ë“  ì›” ìš”ì•½ ì‹œíŠ¸"""
        
        # ì œëª©
        ws.merge_cells('A1:G1')
        title = ws['A1']
        title.value = f"ğŸ“Š ì›”ë³„ í‡´ì†Œ ì‚¬ìœ  ìˆœìœ„ ìš”ì•½"
        title.font = Font(size=16, bold=True, color="FFFFFF")
        title.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        title.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[1].height = 30
        
        # detailed_listì—ì„œ í‡´ì›í•œ í•™ìƒë“¤ë§Œ í•„í„°ë§
        detailed_list = report_data.get("detailed_list", [])
        discharged_students = [
            student for student in detailed_list 
            if student.get("ì¬ì›ìƒíƒœ") == "í‡´ì›" and student.get("í‡´ì†Œì¼ì")
        ]
        
        if not discharged_students:
            ws.cell(row=3, column=1).value = "í‡´ì†Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        
        # í‡´ì†Œì¼ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì›”ë³„ë¡œ ê·¸ë£¹í™”
        monthly_discharges = {}
        for student in discharged_students:
            discharge_date_str = student.get("í‡´ì†Œì¼ì")
            if not discharge_date_str:
                continue
            
            try:
                # ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (ISO í˜•ì‹ ë˜ëŠ” ë‹¤ë¥¸ í˜•ì‹ ì§€ì›)
                if "T" in discharge_date_str:
                    discharge_date = datetime.fromisoformat(discharge_date_str.split("T")[0])
                else:
                    discharge_date = datetime.fromisoformat(discharge_date_str)
                
                year_month = (discharge_date.year, discharge_date.month)
                if year_month not in monthly_discharges:
                    monthly_discharges[year_month] = []
                
                monthly_discharges[year_month].append(student)
            except Exception:
                continue
        
        # ì›”ë³„ë¡œ ì •ë ¬ (ë…„ë„, ì›” ìˆœì„œ)
        sorted_months = sorted(monthly_discharges.keys())
        
        # ê° ì›”ë³„ ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„
        monthly_data = []
        for year, month in sorted_months:
            students = monthly_discharges[(year, month)]
            
            # í‡´ì†Œ ì‚¬ìœ  ì§‘ê³„
            reasons = []
            for student in students:
                r = student.get('í‡´ì›ì‚¬ìœ ') or student.get('í‡´ì†Œì‚¬ìœ ') or student.get('discharging_reason')
                if not r:
                    r = 'ê¸°íƒ€'
                if isinstance(r, str):
                    r = r.strip() or 'ê¸°íƒ€'
                else:
                    r = str(r)
                reasons.append(r)
            
            counts = Counter(reasons)
            sorted_reasons = counts.most_common()
            
            monthly_data.append({
                'year': year,
                'month': month,
                'reasons': sorted_reasons
            })
        
        # 3í–‰ 4ì—´ ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
        # ê° ì›”ë³„ ë°•ìŠ¤ëŠ” 4ì—´ ë„ˆë¹„ (A~D, E~H, I~L, M~P)
        # ê° í–‰ì˜ ì‹œì‘ ì—´: A(1), E(5), I(9), M(13)
        cols_per_month = 4
        start_cols = [1, 5, 9, 13]  # A, E, I, M
        
        # ê° ì›”ë³„ ë°•ìŠ¤ì˜ ìµœëŒ€ ë†’ì´ ê³„ì‚° (ì œëª© 1í–‰ + í—¤ë” 1í–‰ + ë°ì´í„° ìµœëŒ€ 10í–‰)
        max_rows_per_month = 12
        
        # 3í–‰ 4ì—´ ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
        for month_idx, month_info in enumerate(monthly_data):
            year = month_info['year']
            month = month_info['month']
            sorted_reasons = month_info['reasons']
            
            # ê·¸ë¦¬ë“œ ìœ„ì¹˜ ê³„ì‚° (3í–‰ 4ì—´)
            grid_row = month_idx // 4  # 0, 1, 2
            grid_col = month_idx % 4   # 0, 1, 2, 3
            
            # ì‹¤ì œ Excel í–‰/ì—´ ê³„ì‚°
            start_col = start_cols[grid_col]
            start_row = 3 + (grid_row * max_rows_per_month)
            
            # ì›”ë³„ ì„¹ì…˜ ì œëª©
            end_col = start_col + cols_per_month - 1
            ws.merge_cells(f'{get_column_letter(start_col)}{start_row}:{get_column_letter(end_col)}{start_row}')
            sec_title = ws[f'{get_column_letter(start_col)}{start_row}']
            sec_title.value = f"ğŸ“… {year}ë…„ {month}ì›”"
            sec_title.font = Font(size=11, bold=True, color="FFFFFF")
            sec_title.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            sec_title.alignment = Alignment(horizontal="center", vertical="center")
            
            current_row = start_row + 1
            
            if sorted_reasons:
                # í…Œì´ë¸” í—¤ë”
                headers = ["ìˆœìœ„", "ì‚¬ìœ ", "ê±´ìˆ˜"]
                for col_offset, header in enumerate(headers):
                    col = start_col + col_offset
                    cell = ws.cell(row=current_row, column=col)
                    cell.value = header
                    cell.fill = PatternFill(start_color="70AD47", end_color="70AD47", fill_type="solid")
                    cell.font = Font(color="FFFFFF", bold=True, size=9)
                    cell.alignment = Alignment(horizontal="center", vertical="center")
                
                current_row += 1
                
                # ë°ì´í„° í–‰ (ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ í‘œì‹œ)
                for idx, (reason, cnt) in enumerate(sorted_reasons[:10], 1):
                    ws.cell(row=current_row, column=start_col).value = idx
                    ws.cell(row=current_row, column=start_col + 1).value = reason[:15] if len(reason) > 15 else reason  # ì‚¬ìœ ëŠ” ìµœëŒ€ 15ì
                    ws.cell(row=current_row, column=start_col + 2).value = f"{cnt}ê±´"
                    
                    # ìŠ¤íŠ¸ë¼ì´í”„ ìŠ¤íƒ€ì¼
                    if current_row % 2 == 0:
                        for c in range(start_col, start_col + 3):
                            ws.cell(row=current_row, column=c).fill = PatternFill(
                                start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                            )
                    
                    # ì‘ì€ í°íŠ¸
                    for c in range(start_col, start_col + 3):
                        ws.cell(row=current_row, column=c).font = Font(size=9)
                        ws.cell(row=current_row, column=c).alignment = Alignment(horizontal="center", vertical="center")
                    
                    current_row += 1
            else:
                ws.cell(row=current_row, column=start_col).value = "ë°ì´í„° ì—†ìŒ"
                ws.cell(row=current_row, column=start_col).font = Font(size=9)
                ws.cell(row=current_row, column=start_col).alignment = Alignment(horizontal="center", vertical="center")
        
        # ì—´ ë„ˆë¹„ ì¡°ì • (ê° ì›”ë³„ ë°•ìŠ¤ì˜ ì—´)
        for col_letter in ['A', 'E', 'I', 'M']:
            ws.column_dimensions[col_letter].width = 6  # ìˆœìœ„
        for col_letter in ['B', 'F', 'J', 'N']:
            ws.column_dimensions[col_letter].width = 18  # ì‚¬ìœ 
        for col_letter in ['C', 'G', 'K', 'O']:
            ws.column_dimensions[col_letter].width = 8   # ê±´ìˆ˜
        # ë¹ˆ ì—´ (ê°„ê²©ìš©)
        for col_letter in ['D', 'H', 'L', 'P']:
            ws.column_dimensions[col_letter].width = 2
        
        # ===== ì „ì²´ ì›” í‡´ì†Œì‚¬ìœ  ìš”ì•½ (ì˜¤ë¥¸ìª½) =====
        # ì „ì²´ í‡´ì†Œì‚¬ìœ  ì§‘ê³„
        all_reasons = []
        for student in discharged_students:
            r = student.get('í‡´ì›ì‚¬ìœ ') or student.get('í‡´ì†Œì‚¬ìœ ') or student.get('discharging_reason')
            if not r:
                r = 'ê¸°íƒ€'
            if isinstance(r, str):
                r = r.strip() or 'ê¸°íƒ€'
            else:
                r = str(r)
            all_reasons.append(r)
        
        all_counts = Counter(all_reasons)
        all_sorted_reasons = all_counts.most_common()
        
        # ì „ì²´ ìš”ì•½ ì„¹ì…˜ ì‹œì‘ ìœ„ì¹˜ (Rì—´ë¶€í„°, í•œ ì¹¸ ë” ë„ì›€)
        summary_start_col = 18  # Rì—´ (Qì—´ì—ì„œ í•œ ì¹¸ ì˜¤ë¥¸ìª½)
        summary_start_row = 3
        
        # ì „ì²´ ìš”ì•½ ì œëª© (2í–‰ ë†’ì´ë¡œ í™•ì¥)
        ws.merge_cells(f'{get_column_letter(summary_start_col)}{summary_start_row}:{get_column_letter(summary_start_col + 2)}{summary_start_row + 1}')
        summary_title = ws[f'{get_column_letter(summary_start_col)}{summary_start_row}']
        summary_title.value = "ğŸ“Š ì „ì²´ ì›” í‡´ì†Œì‚¬ìœ  ìš”ì•½"
        summary_title.font = Font(size=16, bold=True, color="FFFFFF")
        summary_title.fill = PatternFill(start_color="C55A11", end_color="C55A11", fill_type="solid")  # ì£¼í™©ìƒ‰ ê³„ì—´ë¡œ ë³€ê²½
        summary_title.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[summary_start_row].height = 40  # ì œëª© í–‰ ë†’ì´ ì¦ê°€
        ws.row_dimensions[summary_start_row + 1].height = 40  # ì œëª© í–‰ ë†’ì´ ì¦ê°€
        
        current_summary_row = summary_start_row + 2
        
        if all_sorted_reasons:
            # í…Œì´ë¸” í—¤ë”
            headers = ["ìˆœìœ„", "ì‚¬ìœ ", "ê±´ìˆ˜"]
            for col_offset, header in enumerate(headers):
                col = summary_start_col + col_offset
                cell = ws.cell(row=current_summary_row, column=col)
                cell.value = header
                cell.fill = PatternFill(start_color="70AD47", end_color="70AD47", fill_type="solid")
                cell.font = Font(color="FFFFFF", bold=True, size=10)
                cell.alignment = Alignment(horizontal="center", vertical="center")
            
            current_summary_row += 1
            
            # ë°ì´í„° í–‰
            for idx, (reason, cnt) in enumerate(all_sorted_reasons, 1):
                ws.cell(row=current_summary_row, column=summary_start_col).value = idx
                ws.cell(row=current_summary_row, column=summary_start_col + 1).value = reason
                ws.cell(row=current_summary_row, column=summary_start_col + 2).value = f"{cnt}ê±´"
                
                # ìŠ¤íŠ¸ë¼ì´í”„ ìŠ¤íƒ€ì¼
                if current_summary_row % 2 == 0:
                    for c in range(summary_start_col, summary_start_col + 3):
                        ws.cell(row=current_summary_row, column=c).fill = PatternFill(
                            start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                        )
                
                # í°íŠ¸ ë° ì •ë ¬
                for c in range(summary_start_col, summary_start_col + 3):
                    ws.cell(row=current_summary_row, column=c).font = Font(size=10)
                    ws.cell(row=current_summary_row, column=c).alignment = Alignment(horizontal="center", vertical="center")
                
                current_summary_row += 1
        else:
            ws.cell(row=current_summary_row, column=summary_start_col).value = "ë°ì´í„° ì—†ìŒ"
            ws.cell(row=current_summary_row, column=summary_start_col).font = Font(size=10)
            ws.cell(row=current_summary_row, column=summary_start_col).alignment = Alignment(horizontal="center", vertical="center")
        
        # ì „ì²´ ìš”ì•½ ì—´ ë„ˆë¹„ ì¡°ì • (R, S, Tì—´)
        ws.column_dimensions['R'].width = 6   # ìˆœìœ„
        ws.column_dimensions['S'].width = 25  # ì‚¬ìœ 
        ws.column_dimensions['T'].width = 10  # ê±´ìˆ˜
    
    def _create_class_summary_sheet(self, ws, report_data: Dict):
        """ê³¼ëª©ë³„ í‡´ì†Œ ì‚¬ìœ  ìˆœìœ„ ìš”ì•½ ì‹œíŠ¸"""
        
        # ì œëª©
        ws.merge_cells('A1:G1')
        title = ws['A1']
        title.value = f"ğŸ“Š ê³¼ëª©ë³„ í‡´ì†Œ ì‚¬ìœ  ìˆœìœ„ ìš”ì•½"
        title.font = Font(size=16, bold=True, color="FFFFFF")
        title.fill = PatternFill(start_color="7030A0", end_color="7030A0", fill_type="solid")
        title.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[1].height = 30
        
        # detailed_listì—ì„œ í‡´ì›í•œ í•™ìƒë“¤ë§Œ í•„í„°ë§
        detailed_list = report_data.get("detailed_list", [])
        discharged_students = [
            student for student in detailed_list 
            if student.get("ì¬ì›ìƒíƒœ") == "í‡´ì›" and student.get("í‡´ì†Œì¼ì")
        ]
        
        if not discharged_students:
            ws.cell(row=3, column=1).value = "í‡´ì†Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        
        # ê³¼ëª©ë³„ë¡œ ê·¸ë£¹í™”
        subject_discharges = {}
        for student in discharged_students:
            subject = student.get("ë°˜", "ê¸°íƒ€")
            # ë°˜ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(subject, list):
                subjects = subject
            elif isinstance(subject, str) and "," in subject:
                subjects = [s.strip() for s in subject.split(",")]
            else:
                subjects = [subject] if subject else ["ê¸°íƒ€"]
            
            for subj in subjects:
                if subj not in subject_discharges:
                    subject_discharges[subj] = []
                subject_discharges[subj].append(student)
        
        # ê³¼ëª©ë³„ë¡œ ì •ë ¬
        sorted_subjects = sorted(subject_discharges.keys())
        
        # ê° ê³¼ëª©ë³„ ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„
        subject_data = []
        for subject in sorted_subjects:
            students = subject_discharges[subject]
            
            # í‡´ì†Œ ì‚¬ìœ  ì§‘ê³„
            reasons = []
            for student in students:
                r = student.get('í‡´ì›ì‚¬ìœ ') or student.get('í‡´ì†Œì‚¬ìœ ') or student.get('discharging_reason')
                if not r:
                    r = 'ê¸°íƒ€'
                if isinstance(r, str):
                    r = r.strip() or 'ê¸°íƒ€'
                else:
                    r = str(r)
                reasons.append(r)
            
            counts = Counter(reasons)
            sorted_reasons = counts.most_common()
            
            subject_data.append({
                'subject': subject,
                'reasons': sorted_reasons
            })
        
        # 3í–‰ 4ì—´ ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
        # ê° ê³¼ëª©ë³„ ë°•ìŠ¤ëŠ” 4ì—´ ë„ˆë¹„ (A~D, E~H, I~L, M~P)
        # ê° í–‰ì˜ ì‹œì‘ ì—´: A(1), E(5), I(9), M(13)
        cols_per_subject = 4
        start_cols = [1, 5, 9, 13]  # A, E, I, M
        
        # ê° ê³¼ëª©ë³„ ë°•ìŠ¤ì˜ ìµœëŒ€ ë†’ì´ ê³„ì‚° (ì œëª© 1í–‰ + í—¤ë” 1í–‰ + ë°ì´í„° ìµœëŒ€ 10í–‰)
        max_rows_per_subject = 12
        
        # 3í–‰ 4ì—´ ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
        for subject_idx, subject_info in enumerate(subject_data):
            subject = subject_info['subject']
            sorted_reasons = subject_info['reasons']
            
            # ê·¸ë¦¬ë“œ ìœ„ì¹˜ ê³„ì‚° (3í–‰ 4ì—´)
            grid_row = subject_idx // 4  # 0, 1, 2
            grid_col = subject_idx % 4   # 0, 1, 2, 3
            
            # ì‹¤ì œ Excel í–‰/ì—´ ê³„ì‚°
            start_col = start_cols[grid_col]
            start_row = 3 + (grid_row * max_rows_per_subject)
            
            # ê³¼ëª©ë³„ ì„¹ì…˜ ì œëª©
            end_col = start_col + cols_per_subject - 1
            ws.merge_cells(f'{get_column_letter(start_col)}{start_row}:{get_column_letter(end_col)}{start_row}')
            sec_title = ws[f'{get_column_letter(start_col)}{start_row}']
            sec_title.value = f"ğŸ“š {subject}"
            sec_title.font = Font(size=11, bold=True, color="FFFFFF")
            sec_title.fill = PatternFill(start_color="7030A0", end_color="7030A0", fill_type="solid")
            sec_title.alignment = Alignment(horizontal="center", vertical="center")
            
            current_row = start_row + 1
            
            if sorted_reasons:
                # í…Œì´ë¸” í—¤ë”
                headers = ["ìˆœìœ„", "ì‚¬ìœ ", "ê±´ìˆ˜"]
                for col_offset, header in enumerate(headers):
                    col = start_col + col_offset
                    cell = ws.cell(row=current_row, column=col)
                    cell.value = header
                    cell.fill = PatternFill(start_color="70AD47", end_color="70AD47", fill_type="solid")
                    cell.font = Font(color="FFFFFF", bold=True, size=9)
                    cell.alignment = Alignment(horizontal="center", vertical="center")
                
                current_row += 1
                
                # ë°ì´í„° í–‰ (ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ í‘œì‹œ)
                for idx, (reason, cnt) in enumerate(sorted_reasons[:10], 1):
                    ws.cell(row=current_row, column=start_col).value = idx
                    ws.cell(row=current_row, column=start_col + 1).value = reason[:15] if len(reason) > 15 else reason  # ì‚¬ìœ ëŠ” ìµœëŒ€ 15ì
                    ws.cell(row=current_row, column=start_col + 2).value = f"{cnt}ê±´"
                    
                    # ìŠ¤íŠ¸ë¼ì´í”„ ìŠ¤íƒ€ì¼
                    if current_row % 2 == 0:
                        for c in range(start_col, start_col + 3):
                            ws.cell(row=current_row, column=c).fill = PatternFill(
                                start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                            )
                    
                    # ì‘ì€ í°íŠ¸
                    for c in range(start_col, start_col + 3):
                        ws.cell(row=current_row, column=c).font = Font(size=9)
                        ws.cell(row=current_row, column=c).alignment = Alignment(horizontal="center", vertical="center")
                    
                    current_row += 1
            else:
                ws.cell(row=current_row, column=start_col).value = "ë°ì´í„° ì—†ìŒ"
                ws.cell(row=current_row, column=start_col).font = Font(size=9)
                ws.cell(row=current_row, column=start_col).alignment = Alignment(horizontal="center", vertical="center")
        
        # ì—´ ë„ˆë¹„ ì¡°ì • (ê° ê³¼ëª©ë³„ ë°•ìŠ¤ì˜ ì—´)
        for col_letter in ['A', 'E', 'I', 'M']:
            ws.column_dimensions[col_letter].width = 6  # ìˆœìœ„
        for col_letter in ['B', 'F', 'J', 'N']:
            ws.column_dimensions[col_letter].width = 18  # ì‚¬ìœ 
        for col_letter in ['C', 'G', 'K', 'O']:
            ws.column_dimensions[col_letter].width = 8   # ê±´ìˆ˜
        # ë¹ˆ ì—´ (ê°„ê²©ìš©)
        for col_letter in ['D', 'H', 'L', 'P']:
            ws.column_dimensions[col_letter].width = 2
        
        # ===== ì „ì²´ ê³¼ëª© í‡´ì†Œì‚¬ìœ  ìš”ì•½ (ì˜¤ë¥¸ìª½) =====
        # ì „ì²´ í‡´ì†Œì‚¬ìœ  ì§‘ê³„
        all_reasons = []
        for student in discharged_students:
            r = student.get('í‡´ì›ì‚¬ìœ ') or student.get('í‡´ì†Œì‚¬ìœ ') or student.get('discharging_reason')
            if not r:
                r = 'ê¸°íƒ€'
            if isinstance(r, str):
                r = r.strip() or 'ê¸°íƒ€'
            else:
                r = str(r)
            all_reasons.append(r)
        
        all_counts = Counter(all_reasons)
        all_sorted_reasons = all_counts.most_common()
        
        # ì „ì²´ ìš”ì•½ ì„¹ì…˜ ì‹œì‘ ìœ„ì¹˜ (Rì—´ë¶€í„°, í•œ ì¹¸ ë” ë„ì›€)
        summary_start_col = 18  # Rì—´ (Qì—´ì—ì„œ í•œ ì¹¸ ì˜¤ë¥¸ìª½)
        summary_start_row = 3
        
        # ì „ì²´ ìš”ì•½ ì œëª© (2í–‰ ë†’ì´ë¡œ í™•ì¥)
        ws.merge_cells(f'{get_column_letter(summary_start_col)}{summary_start_row}:{get_column_letter(summary_start_col + 2)}{summary_start_row + 1}')
        summary_title = ws[f'{get_column_letter(summary_start_col)}{summary_start_row}']
        summary_title.value = "ğŸ“Š ì „ì²´ ê³¼ëª© í‡´ì†Œì‚¬ìœ  ìš”ì•½"
        summary_title.font = Font(size=16, bold=True, color="FFFFFF")
        summary_title.fill = PatternFill(start_color="C55A11", end_color="C55A11", fill_type="solid")  # ì£¼í™©ìƒ‰ ê³„ì—´ë¡œ ë³€ê²½
        summary_title.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[summary_start_row].height = 40  # ì œëª© í–‰ ë†’ì´ ì¦ê°€
        ws.row_dimensions[summary_start_row + 1].height = 40  # ì œëª© í–‰ ë†’ì´ ì¦ê°€
        
        current_summary_row = summary_start_row + 2
        
        if all_sorted_reasons:
            # í…Œì´ë¸” í—¤ë”
            headers = ["ìˆœìœ„", "ì‚¬ìœ ", "ê±´ìˆ˜"]
            for col_offset, header in enumerate(headers):
                col = summary_start_col + col_offset
                cell = ws.cell(row=current_summary_row, column=col)
                cell.value = header
                cell.fill = PatternFill(start_color="70AD47", end_color="70AD47", fill_type="solid")
                cell.font = Font(color="FFFFFF", bold=True, size=10)
                cell.alignment = Alignment(horizontal="center", vertical="center")
            
            current_summary_row += 1
            
            # ë°ì´í„° í–‰
            for idx, (reason, cnt) in enumerate(all_sorted_reasons, 1):
                ws.cell(row=current_summary_row, column=summary_start_col).value = idx
                ws.cell(row=current_summary_row, column=summary_start_col + 1).value = reason
                ws.cell(row=current_summary_row, column=summary_start_col + 2).value = f"{cnt}ê±´"
                
                # ìŠ¤íŠ¸ë¼ì´í”„ ìŠ¤íƒ€ì¼
                if current_summary_row % 2 == 0:
                    for c in range(summary_start_col, summary_start_col + 3):
                        ws.cell(row=current_summary_row, column=c).fill = PatternFill(
                            start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                        )
                
                # í°íŠ¸ ë° ì •ë ¬
                for c in range(summary_start_col, summary_start_col + 3):
                    ws.cell(row=current_summary_row, column=c).font = Font(size=10)
                    ws.cell(row=current_summary_row, column=c).alignment = Alignment(horizontal="center", vertical="center")
                
                current_summary_row += 1
        else:
            ws.cell(row=current_summary_row, column=summary_start_col).value = "ë°ì´í„° ì—†ìŒ"
            ws.cell(row=current_summary_row, column=summary_start_col).font = Font(size=10)
            ws.cell(row=current_summary_row, column=summary_start_col).alignment = Alignment(horizontal="center", vertical="center")
        
        # ì „ì²´ ìš”ì•½ ì—´ ë„ˆë¹„ ì¡°ì • (R, S, Tì—´)
        ws.column_dimensions['R'].width = 6   # ìˆœìœ„
        ws.column_dimensions['S'].width = 25  # ì‚¬ìœ 
        ws.column_dimensions['T'].width = 10  # ê±´ìˆ˜
    
    def _parse_duration_to_days(self, duration_str: str) -> int:
        """ì¬ì›ê¸°ê°„ ë¬¸ìì—´ì„ ì¼ìˆ˜ë¡œ ë³€í™˜"""
        if not duration_str or duration_str == "-":
            return 0
        try:
            days = 0
            # "Xê°œì›” Yì¼" í˜•ì‹ íŒŒì‹±
            if "ê°œì›”" in duration_str:
                months = int(re.search(r'(\d+)ê°œì›”', duration_str).group(1))
                days += months * 30
            if "ì¼" in duration_str:
                day_part = re.search(r'(\d+)ì¼', duration_str)
                if day_part:
                    days += int(day_part.group(1))
            return days
        except:
            return 0
    
    def _create_detail_sheet(self, ws, report_data: Dict):
        """í•™ìƒë³„ ìƒì„¸ ëª…ë‹¨ ì‹œíŠ¸ (ì…ì†Œ/í‡´ì†Œ ë¶„ë¦¬)"""
        detailed = report_data["detailed_list"]
        
        if not detailed:
            ws['A1'] = "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        
        # ì…ì†Œ í•™ìƒê³¼ í‡´ì†Œ í•™ìƒìœ¼ë¡œ ë¶„ë¦¬
        enrolled_students = [s for s in detailed if s.get("ì¬ì›ìƒíƒœ") == "ì¬ì›ì¤‘"]
        discharged_students = [s for s in detailed if s.get("ì¬ì›ìƒíƒœ") == "í‡´ì›"]
        
        # í‡´ì†Œ í•™ìƒ ì¬ì›ê¸°ê°„ í‰ê·  ê³„ì‚°
        discharged_durations = []
        for student in discharged_students:
            duration_str = student.get("ì¬ì›ê¸°ê°„", "")
            days = self._parse_duration_to_days(duration_str)
            if days > 0:
                discharged_durations.append(days)
        
        avg_duration_days = sum(discharged_durations) / len(discharged_durations) if discharged_durations else 0
        if avg_duration_days >= 30:
            avg_months = int(avg_duration_days // 30)
            avg_remaining_days = int(avg_duration_days % 30)
            if avg_remaining_days > 0:
                avg_duration_str = f"{avg_months}ê°œì›” {avg_remaining_days}ì¼"
            else:
                avg_duration_str = f"{avg_months}ê°œì›”"
        else:
            avg_duration_str = f"{int(avg_duration_days)}ì¼"
        
        # ì œëª©
        ws.merge_cells('A1:G1')
        title = ws['A1']
        title.value = "ğŸ‘¥ í•™ìƒë³„ ìƒì„¸ ëª…ë‹¨"
        title.font = Font(size=14, bold=True, color="FFFFFF")
        title.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        title.alignment = Alignment(horizontal="center")
        ws.row_dimensions[1].height = 25
        
        current_row = 3
        
        # ì…ì†Œ í•™ìƒê³¼ í‡´ì†Œ í•™ìƒ ë°ì´í„° ì¤€ë¹„
        df_enrolled = pd.DataFrame(enrolled_students) if enrolled_students else pd.DataFrame()
        df_discharged = pd.DataFrame(discharged_students) if discharged_students else pd.DataFrame()
        
        # ì…ì†Œ í•™ìƒ ë°ì´í„°ì—ì„œ í‡´ì†Œì¼ìì™€ í‡´ì›ì‚¬ìœ  ì»¬ëŸ¼ ì œê±°
        if not df_enrolled.empty:
            columns_to_drop = ['í‡´ì†Œì¼ì', 'í‡´ì›ì‚¬ìœ ']
            existing_columns_to_drop = [col for col in columns_to_drop if col in df_enrolled.columns]
            if existing_columns_to_drop:
                df_enrolled = df_enrolled.drop(columns=existing_columns_to_drop)
        
        # í‡´ì†Œ í•™ìƒ ì»¬ëŸ¼ ìˆ˜
        discharged_cols = len(df_discharged.columns) if not df_discharged.empty else 0
        # ì…ì†Œ í•™ìƒ ì‹œì‘ ì—´ (í‡´ì†Œ í•™ìƒ ì»¬ëŸ¼ + ê°„ê²© 2ì—´)
        enrolled_start_col = discharged_cols + 3 if discharged_cols > 0 else 1
        
        # ===== í‡´ì†Œ í•™ìƒ ì„¹ì…˜ (ì™¼ìª½) =====
        if not df_discharged.empty:
            # í‡´ì†Œ í•™ìƒ ì„¹ì…˜ ì œëª©
            ws.merge_cells(f'A{current_row}:{get_column_letter(discharged_cols)}{current_row}')
            section_title = ws[f'A{current_row}']
            section_title.value = "ğŸ“Œ í‡´ì†Œ í•™ìƒ"
            section_title.font = Font(size=12, bold=True, color="FFFFFF")
            section_title.fill = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")
            section_title.alignment = Alignment(horizontal="left")
            current_row += 1
            
            # í—¤ë”
            for col_num, column in enumerate(df_discharged.columns, 1):
                cell = ws.cell(row=current_row, column=col_num)
                cell.value = column
                cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
                cell.font = Font(color="FFFFFF", bold=True)
                cell.alignment = Alignment(horizontal="center")
            
            # ì¬ì›ê¸°ê°„ í‰ê·  í‘œì‹œ (G2 ì…€)
            avg_cell = ws['G2']
            avg_cell.value = f"í‰ê·  ì¬ì›ê¸°ê°„: {avg_duration_str}"
            avg_cell.font = Font(size=11, bold=True, color="FFFFFF")
            avg_cell.fill = PatternFill(start_color="C55A11", end_color="C55A11", fill_type="solid")
            avg_cell.alignment = Alignment(horizontal="center", vertical="center")
            
            current_row += 1
            
            # ë°ì´í„°
            discharged_data_start_row = current_row
            for row_idx, row_data in enumerate(df_discharged.values):
                for col_num, value in enumerate(row_data, 1):
                    cell = ws.cell(row=current_row, column=col_num)
                    cell.value = value if value is not None else "-"
                    cell.alignment = Alignment(horizontal="left")
                    
                    # ì¬ì›ìƒíƒœ ìƒ‰ìƒ
                    if df_discharged.columns[col_num - 1] == "ì¬ì›ìƒíƒœ":
                        cell.font = Font(color="FF0000", bold=True)
                    
                    # ìŠ¤íŠ¸ë¼ì´í”„
                    if current_row % 2 == 0:
                        cell.fill = PatternFill(start_color="F2F2F2", 
                                               end_color="F2F2F2", fill_type="solid")
                current_row += 1
            
            discharged_data_end_row = current_row - 1
        
        # ===== ì…ì†Œ í•™ìƒ ì„¹ì…˜ (ì˜¤ë¥¸ìª½) =====
        if not df_enrolled.empty:
            # ì…ì†Œ í•™ìƒ ì„¹ì…˜ ì œëª©
            enrolled_cols = len(df_enrolled.columns)
            ws.merge_cells(f'{get_column_letter(enrolled_start_col)}{3}:{get_column_letter(enrolled_start_col + enrolled_cols - 1)}{3}')
            section_title = ws[f'{get_column_letter(enrolled_start_col)}{3}']
            section_title.value = "ğŸ“Œ ì…ì†Œ í•™ìƒ (ì¬ì›ì¤‘)"
            section_title.font = Font(size=12, bold=True, color="FFFFFF")
            section_title.fill = PatternFill(start_color="00B050", end_color="00B050", fill_type="solid")
            section_title.alignment = Alignment(horizontal="left")
            
            # í—¤ë” í–‰ ì„¤ì •
            header_row = 4
            
            # í—¤ë”
            for col_num, column in enumerate(df_enrolled.columns, 1):
                col = enrolled_start_col + col_num - 1
                cell = ws.cell(row=header_row, column=col)
                cell.value = column
                cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
                cell.font = Font(color="FFFFFF", bold=True)
                cell.alignment = Alignment(horizontal="center")
            
            # ë°ì´í„° (í‡´ì†Œ í•™ìƒê³¼ ê°™ì€ í–‰ì— ë§ì¶°ì„œ)
            data_start_row = header_row + 1
            if not df_discharged.empty:
                # í‡´ì†Œ í•™ìƒ ë°ì´í„° ì‹œì‘ í–‰ê³¼ ë§ì¶¤
                data_start_row = discharged_data_start_row
            
            for row_idx, row_data in enumerate(df_enrolled.values):
                data_row = data_start_row + row_idx
                for col_num, value in enumerate(row_data, 1):
                    col = enrolled_start_col + col_num - 1
                    cell = ws.cell(row=data_row, column=col)
                    cell.value = value if value is not None else "-"
                    cell.alignment = Alignment(horizontal="left")
                    
                    # ì¬ì›ìƒíƒœ ìƒ‰ìƒ
                    if df_enrolled.columns[col_num - 1] == "ì¬ì›ìƒíƒœ":
                        cell.font = Font(color="00B050", bold=True)
                    
                    # ìŠ¤íŠ¸ë¼ì´í”„
                    if data_row % 2 == 0:
                        cell.fill = PatternFill(start_color="F2F2F2", 
                                               end_color="F2F2F2", fill_type="solid")
            
            # ìµœì¢… í–‰ ì—…ë°ì´íŠ¸
            if not df_discharged.empty:
                current_row = max(current_row, data_start_row + len(df_enrolled))
            else:
                current_row = data_start_row + len(df_enrolled)
        
        # ì—´ ë„ˆë¹„ ìë™ ì¡°ì • (ê¸€ìì— ë§ì¶°ì„œ)
        max_col = max(discharged_cols, enrolled_start_col + len(df_enrolled.columns) - 1) if not df_enrolled.empty else discharged_cols
        
        # í•œê¸€ ë¬¸ìë¥¼ ê³ ë ¤í•œ ë„ˆë¹„ ê³„ì‚° í•¨ìˆ˜
        def calculate_text_width(text):
            """í•œê¸€ê³¼ ì˜ë¬¸ì„ ê³ ë ¤í•œ í…ìŠ¤íŠ¸ ë„ˆë¹„ ê³„ì‚°"""
            if not text:
                return 0
            text_str = str(text)
            width = 0
            for char in text_str:
                # í•œê¸€, í•œì ë“± ì „ê° ë¬¸ìëŠ” 2ë¡œ ê³„ì‚°
                if ord(char) > 127:
                    width += 2
                else:
                    width += 1
            return width
        
        for col_num in range(1, max_col + 1):
            max_width = 0
            column_letter = get_column_letter(col_num)
            
            # J, Kì—´ì€ ìµœì†Œ ë„ˆë¹„ë¡œ ì„¤ì •
            if column_letter in ['J', 'K']:
                ws.column_dimensions[column_letter].width = 3  # ìµœì†Œ ë„ˆë¹„
                continue
            
            # Pì—´ì€ í‰ê·  ì¬ì›ê¸°ê°„ ì…€(P2) í¬ê¸°ì— ë§ì¶°ì„œ ì¡°ì •
            if column_letter == 'G':
                # P2 ì…€ì˜ í…ìŠ¤íŠ¸ í¬ê¸° í™•ì¸
                g2_cell = ws['G2']
                if g2_cell.value:
                    text_width = calculate_text_width(g2_cell.value)
                    ws.column_dimensions[column_letter].width = text_width + 2
                else:
                    ws.column_dimensions[column_letter].width = 10  # ê¸°ë³¸ê°’
                continue
            
            # Sì—´ì€ ê¸€ì í¬ê¸°ì— ë§ì¶°ì„œ ìë™ ì¡°ì •
            if column_letter == 'S':
                for row in ws.iter_rows(min_row=3, max_row=current_row, min_col=col_num, max_col=col_num):
                    for cell in row:
                        try:
                            if cell.value:
                                text_width = calculate_text_width(cell.value)
                                if text_width > max_width:
                                    max_width = text_width
                        except:
                            pass
                # Sì—´ ë„ˆë¹„ ì„¤ì • (í…ìŠ¤íŠ¸ ë„ˆë¹„ + ì—¬ìœ  ê³µê°„ 2)
                if max_width > 0:
                    ws.column_dimensions[column_letter].width = max_width + 2
                else:
                    ws.column_dimensions[column_letter].width = 10  # ê¸°ë³¸ê°’
                continue
            
            # ë‚˜ë¨¸ì§€ ì—´ì€ ì¼ë°˜ ìë™ ì¡°ì •
            for row in ws.iter_rows(min_row=3, max_row=current_row, min_col=col_num, max_col=col_num):
                for cell in row:
                    try:
                        if cell.value:
                            text_width = calculate_text_width(cell.value)
                            if text_width > max_width:
                                max_width = text_width
                    except:
                        pass
            # ì—´ ë„ˆë¹„ ì„¤ì • (í…ìŠ¤íŠ¸ ë„ˆë¹„ + ì—¬ìœ  ê³µê°„ 2)
            if max_width > 0:
                ws.column_dimensions[column_letter].width = max_width + 2
            else:
                ws.column_dimensions[column_letter].width = 10  # ê¸°ë³¸ê°’


####

    
     
      

####

class ReportOrchestrator:
    def __init__(self):
        self.notion = NotionManager()
        self.ai = OllamaAnalyzer()
        self.discharge_report = EnhancedDischargeReportGenerator(self.notion)
        #self.pdf = PDFConverter()
        #self.security = SecurityManager()
        #self.file_manager = LocalFileManager()
    
    async def _process_discharge_report(self, query_results: Dict, query: ReportQuery):
        """ì…í‡´ì†Œ ë³´ê³ ì„œ (ì°¨íŠ¸ í¬í•¨)"""
        
        if isinstance(query, list):
            q0 = query[0]
        else:
            q0 = query

        teacher_name = q0.filters.get("teacher_name")
        
        # ë‚ ì§œ ë²”ìœ„ì—ì„œ ë…„ì›” ì¶”ì¶œ
        year = datetime.now().year
        month = datetime.now().month
        
        if q0.date_range:
            try:
                # date_rangeì˜ end ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë…„ì›” ì¶”ì¶œ (ë˜ëŠ” start ë‚ ì§œ)
                date_str = q0.date_range.get("end") or q0.date_range.get("start")
                if date_str:
                    if "T" in date_str:
                        date_obj = datetime.fromisoformat(date_str.split("T")[0])
                    else:
                        date_obj = datetime.fromisoformat(date_str)
                    year = date_obj.year
                    month = date_obj.month
            except Exception as e:
                logger.warning(f"âš ï¸ ë‚ ì§œ ë²”ìœ„ íŒŒì‹± ì‹¤íŒ¨, í˜„ì¬ ë‚ ì§œ ì‚¬ìš©: {str(e)}")

        # ë³´ê³ ì„œ ë°ì´í„° ìƒì„±
        report_data = await self.discharge_report.generate_monthly_report(
            query_results, teacher_name, year, month
        )
        
        # ì°¨íŠ¸ í¬í•¨ Excel ìƒì„±
        filename = f"discharge_chart_{teacher_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        excel_path = self.discharge_report.create_excel_with_chart(
            report_data, filename
        )

    async def process_request(self, request: ReportRequest):
        """ë³´ê³ ì„œ ìš”ì²­ ì „ì²´ ì²˜ë¦¬"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ”¨ ì²˜ë¦¬ ì‹œì‘: {request.requester_name}ë‹˜ì˜ ìš”ì²­")
        logger.info(f"   ì§ˆë¬¸: {request.question}")
        logger.info(f"{'='*60}\n")
        
        try:
            # ìƒíƒœ ì—…ë°ì´íŠ¸: ê²€í† ì¤‘
            await self.notion.update_request_status(request.id, "ê²€í† ì¤‘")

            # 1. ìì—°ì–´ ì§ˆë¬¸ ë¶„ì„ -> ì¿¼ë¦¬ ìƒì„±
            query = await self.ai.analyze_question(request.question)
            
            # 2. ì¿¼ë¦¬ ì‹¤í–‰ ë° ë°ì´í„° ìˆ˜ì§‘
            query_results = await self.notion.query_multiple_tables(query)
            
            # 3. ë³´ê³ ì„œ ìƒì„± ë° ì „ë‹¬
            await self._process_discharge_report(query_results, query)

            # ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
            await self.notion.update_request_status(request.id, "ì™„ë£Œë¨")
            logger.info(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!\n{'='*60}\n")
            return
        except Exception as e:
            logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            await self.notion.update_request_status(
                request.id, "ì‹¤íŒ¨", error=str(e)
            )

####

@dataclass
class DataImportRequest:
    """ë°ì´í„° ì…ë ¥ ìš”ì²­"""
    table_type: str
    dataframe: pd.DataFrame
    file_infos: List[Dict[str, Any]] = field(default_factory=list)  # ì²˜ë¦¬í•  íŒŒì¼ ì •ë³´ ëª©ë¡
    id: str = field(default_factory=lambda: f"data_import_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}")
    _is_data_import: bool = True
    _retry_count: int = 0

class PollingSystem:
    def __init__(self):
        self.orchestrator = ReportOrchestrator()
        self.is_running = False
        self.queue = asyncio.PriorityQueue()  # ìš°ì„ ìˆœìœ„ íë¡œ ë³€ê²½
        self.processed_ids = set()  # ì²˜ë¦¬ ì¤‘ì´ê±°ë‚˜ ì™„ë£Œëœ ìš”ì²­ ID ì¶”ì 
        self.worker_tasks = []  # ì—¬ëŸ¬ ì›Œì»¤ íƒœìŠ¤í¬ ì €ì¥
        self.polling_task = None
        self.is_processing_report = False  # ë³´ê³ ì„œ ìƒì„± ì¤‘ í”Œë˜ê·¸
        self.report_lock = asyncio.Lock()  # ë³´ê³ ì„œ ìƒì„± ë½
        self._queue_order = 0  # íì— ì¶”ê°€ëœ ìˆœì„œ (ìš°ì„ ìˆœìœ„ê°€ ê°™ì„ ë•Œ ë¹„êµìš©)
    
    async def _worker(self):
        """íì—ì„œ ìš”ì²­ì„ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)"""
        logger.info("ğŸ‘· ì›Œì»¤ ì‹œì‘")
        while self.is_running:
            request = None
            priority = None
            try:
                # íì—ì„œ ìš”ì²­ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ, ìš°ì„ ìˆœìœ„ í)
                try:
                    priority, order, request = await asyncio.wait_for(self.queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                if request is None:
                    continue
                
                # ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì´ê±°ë‚˜ ì™„ë£Œëœ ìš”ì²­ì€ ê±´ë„ˆë›°ê¸°
                if request.id in self.processed_ids:
                    logger.debug(f"â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ ê±´ë„ˆë›°ê¸°: {request.id}")
                    self.queue.task_done()
                    continue
                
                # ë°ì´í„° ì…ë ¥ ì‘ì—…ì¸ ê²½ìš° ë³´ê³ ì„œ ìƒì„±ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
                is_data_import = getattr(request, '_is_data_import', False)
                if is_data_import and self.is_processing_report:
                    logger.info(f"â³ ë°ì´í„° ì…ë ¥ ëŒ€ê¸° ì¤‘: ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ ëŒ€ê¸°... (ìš”ì²­ ID: {request.id})")
                    # ë³´ê³ ì„œ ìƒì„±ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
                    while self.is_processing_report and self.is_running:
                        await asyncio.sleep(0.5)
                    logger.info(f"âœ… ë°ì´í„° ì…ë ¥ ì‹œì‘: ë³´ê³ ì„œ ìƒì„± ì™„ë£Œë¨ (ìš”ì²­ ID: {request.id})")
                
                logger.info(f"ğŸ“ íì—ì„œ ìš”ì²­ ê°€ì ¸ì˜´: {request.id} (ìš°ì„ ìˆœìœ„: {priority}, í í¬ê¸°: {self.queue.qsize()})")
                
                # ì²˜ë¦¬ ì‹œë„
                try:
                    # ì²˜ë¦¬ ì‹œì‘ ì‹œ processed_idsì— ì¶”ê°€ (ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€)
                    self.processed_ids.add(request.id)
                    
                    # ë³´ê³ ì„œ ìƒì„± ì‘ì—…ì¸ ê²½ìš° í”Œë˜ê·¸ ì„¤ì •
                    if not is_data_import:
                        async with self.report_lock:
                            self.is_processing_report = True
                            logger.info(f"ğŸ“Š ë³´ê³ ì„œ ìƒì„± ì‹œì‘: {request.id}")
                    
                    # ë°ì´í„° ì…ë ¥ ì‘ì—… ì²˜ë¦¬
                    if is_data_import:
                        await self._process_data_import(request)
                    else:
                        # ë³´ê³ ì„œ ìƒì„± ì‘ì—… ì²˜ë¦¬
                        await self.orchestrator.process_request(request)
                    
                    logger.info(f"âœ… ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: {request.id}")
                except Exception as e:
                    logger.error(f"âŒ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {request.id}, ì˜¤ë¥˜: {str(e)}")
                    # ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ processed_idsì—ì„œ ì œê±°í•˜ì—¬ ì¬ì‹œë„ ê°€ëŠ¥í•˜ë„ë¡
                    self.processed_ids.discard(request.id)
                    import traceback
                    logger.error(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
                    # ì‹¤íŒ¨í•œ ìš”ì²­ì„ ë‹¤ì‹œ íì— ë„£ì–´ ì¬ì‹œë„ (ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ìµœëŒ€ 3íšŒ)
                    retry_count = getattr(request, '_retry_count', 0)
                    if retry_count < 3:
                        request._retry_count = retry_count + 1
                        # ì¬ì‹œë„ ì‹œì—ë„ ìˆœì„œ ë²ˆí˜¸ ì¦ê°€
                        self._queue_order += 1
                        await self.queue.put((priority, self._queue_order, request))  # ìš°ì„ ìˆœìœ„ ìœ ì§€
                        logger.info(f"ğŸ”„ ìš”ì²­ ì¬ì‹œë„ íì— ì¶”ê°€: {request.id} (ì¬ì‹œë„ {retry_count + 1}/3)")
                finally:
                    # ë³´ê³ ì„œ ìƒì„± ì‘ì—…ì¸ ê²½ìš° í”Œë˜ê·¸ í•´ì œ
                    if not is_data_import:
                        async with self.report_lock:
                            self.is_processing_report = False
                            logger.info(f"ğŸ“Š ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {request.id}")
                    # í ì‘ì—… ì™„ë£Œ í‘œì‹œ (ì„±ê³µ/ì‹¤íŒ¨ ê´€ê³„ì—†ì´)
                    self.queue.task_done()
                    
            except Exception as e:
                logger.error(f"âŒ ì›Œì»¤ ì—ëŸ¬: {str(e)}")
                import traceback
                logger.error(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
                if request:
                    self.queue.task_done()
                await asyncio.sleep(1)
    
    async def _process_data_import(self, request: DataImportRequest):
        """ë°ì´í„° ì…ë ¥ ì‘ì—… ì²˜ë¦¬"""
        logger.info(f"ğŸ“¤ [{request.table_type}] Notion DBì— ë°ì´í„° ì¶”ê°€ ì‹œì‘: {len(request.dataframe)}ê°œ í–‰")
        
        added_count = 0
        failed_count = 0
        
        for idx, row in request.dataframe.iterrows():
            try:
                # DataFrame í–‰ì„ Notion ì†ì„±ìœ¼ë¡œ ë³€í™˜
                properties = excel_importer._convert_dataframe_row_to_notion_properties(
                    row, request.table_type, request.dataframe
                )
                
                if not properties:
                    logger.warning(f"âš ï¸ [{request.table_type}] í–‰ {idx}: ë³€í™˜ëœ ì†ì„±ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                # Notionì— ì¶”ê°€
                await self.orchestrator.notion.client.pages.create(
                    parent={"database_id": self.orchestrator.notion.db_map[request.table_type]},
                    properties=properties
                )
                
                added_count += 1
                if added_count % 10 == 0:
                    logger.info(f"ğŸ“ [{request.table_type}] ì§„í–‰ ì¤‘: {added_count}/{len(request.dataframe)}ê°œ ì¶”ê°€ë¨")
                
                # API ì œí•œ ê³ ë ¤ (ì´ˆë‹¹ 3íšŒ)
                await asyncio.sleep(0.35)
                
            except Exception as e:
                failed_count += 1
                logger.error(f"âŒ [{request.table_type}] í–‰ {idx} ì¶”ê°€ ì‹¤íŒ¨: {e}")
        
        logger.info(f"âœ… [{request.table_type}] Notion DB ì¶”ê°€ ì™„ë£Œ: ì„±ê³µ {added_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
        
        # ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ (í•´ë‹¹ ìš”ì²­ì— í¬í•¨ëœ íŒŒì¼ë“¤ë§Œ ì´ë™)
        if request.file_infos:
            moved_count = excel_handler.move_specific_files_to_imported(request.table_type, request.file_infos)
            logger.info(f"âœ… [{request.table_type}] {moved_count}ê°œ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì™„ë£Œ")
        else:
            logger.warning(f"âš ï¸ [{request.table_type}] ì´ë™í•  íŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    async def _polling(self, interval: int = 30):
        """ì£¼ê¸°ì ìœ¼ë¡œ ìƒˆë¡œìš´ ìš”ì²­ì„ íì— ì¶”ê°€í•˜ëŠ” í´ë§ íƒœìŠ¤í¬"""
        logger.info("ğŸ” í´ë§ ì‹œì‘")
        
        # ì´ˆê¸°í™”: ëŒ€ê¸°ì¤‘ì¸ ëª¨ë“  ìš”ì²­ì„ íì— ì¶”ê°€
        try:
            initial_requests = await self.orchestrator.notion.get_pending_requests()
            for req in initial_requests:
                # ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ì´ì§€ë§Œ ìƒíƒœê°€ ë‹¤ì‹œ "ëŒ€ê¸°ì¤‘"ìœ¼ë¡œ ë³€ê²½ëœ ê²½ìš° ì¬ì²˜ë¦¬
                if req.id in self.processed_ids:
                    logger.info(f"ğŸ”„ ì´ˆê¸°í™”: ì¬ì²˜ë¦¬ ìš”ì²­ ë°œê²¬ (ìƒíƒœê°€ ë‹¤ì‹œ ëŒ€ê¸°ì¤‘ìœ¼ë¡œ ë³€ê²½ë¨): {req.id}")
                    self.processed_ids.discard(req.id)  # processed_idsì—ì„œ ì œê±°í•˜ì—¬ ì¬ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡
                
                if req.id not in self.processed_ids:
                    # ë³´ê³ ì„œ ìƒì„± ìš”ì²­ì€ ìš°ì„ ìˆœìœ„ 2 (ë‚®ìŒ)
                    self._queue_order += 1
                    await self.queue.put((2, self._queue_order, req))
                    logger.info(f"ğŸ“¥ ì´ˆê¸° ìš”ì²­ íì— ì¶”ê°€: {req.id} (ìš°ì„ ìˆœìœ„: 2, í í¬ê¸°: {self.queue.qsize()})")
            logger.info(f"âœ… ì´ˆê¸° {len(initial_requests)}ê°œ ìš”ì²­ íì— ì¶”ê°€ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸° ìš”ì²­ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ìƒˆë¡œìš´ ìš”ì²­ í™•ì¸
        while self.is_running:
            try:
                await asyncio.sleep(interval)
                
                if not self.is_running:
                    break
                
                requests = await self.orchestrator.notion.get_pending_requests()
                
                # ìƒˆë¡œìš´ ìš”ì²­ë§Œ íì— ì¶”ê°€ (processed_idsì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ - ì›Œì»¤ì—ì„œ ì²˜ë¦¬í•  ë•Œ ì¶”ê°€)
                new_count = 0
                for req in requests:
                    # ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ì´ì§€ë§Œ ìƒíƒœê°€ ë‹¤ì‹œ "ëŒ€ê¸°ì¤‘"ìœ¼ë¡œ ë³€ê²½ëœ ê²½ìš° ì¬ì²˜ë¦¬
                    if req.id in self.processed_ids:
                        logger.info(f"ğŸ”„ ì¬ì²˜ë¦¬ ìš”ì²­ ë°œê²¬ (ìƒíƒœê°€ ë‹¤ì‹œ ëŒ€ê¸°ì¤‘ìœ¼ë¡œ ë³€ê²½ë¨): {req.id}")
                        self.processed_ids.discard(req.id)  # processed_idsì—ì„œ ì œê±°í•˜ì—¬ ì¬ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡
                    
                    if req.id not in self.processed_ids:
                        # ë³´ê³ ì„œ ìƒì„± ìš”ì²­ì€ ìš°ì„ ìˆœìœ„ 2 (ë‚®ìŒ)
                        self._queue_order += 1
                        await self.queue.put((2, self._queue_order, req))
                        new_count += 1
                        logger.info(f"ğŸ“¥ ìƒˆ ìš”ì²­ íì— ì¶”ê°€: {req.id} (ìš°ì„ ìˆœìœ„: 2, í í¬ê¸°: {self.queue.qsize()})")
                
                if new_count == 0:
                    logger.info(f"ğŸ’¤ ìƒˆ ìš”ì²­ ì—†ìŒ (í í¬ê¸°: {self.queue.qsize()}) ({datetime.now().strftime('%H:%M:%S')})")
                else:
                    logger.info(f"ğŸ“¥ {new_count}ê°œ ìƒˆ ìš”ì²­ íì— ì¶”ê°€ë¨ (í í¬ê¸°: {self.queue.qsize()})")
                
            except Exception as e:
                logger.error(f"âŒ í´ë§ ì—ëŸ¬: {str(e)}")
    
    async def start(self, interval: int = 30, num_workers: int = 1):
        self.is_running = True
        logger.info("ğŸš€ í•™ì› ë³´ê³ ì„œ ì‹œìŠ¤í…œ ì‹œì‘")
        logger.info(f"â° í´ë§ ê°„ê²©: {interval}ì´ˆ")
        logger.info(f"ğŸ‘· ì›Œì»¤ ìˆ˜: {num_workers}ê°œ")
        logger.info("-" * 60)
        
        # ì›Œì»¤ íƒœìŠ¤í¬ ì‹œì‘ (íì—ì„œ ìš”ì²­ ì²˜ë¦¬)
        self.worker_tasks = []
        for i in range(num_workers):
            task = asyncio.create_task(self._worker())
            self.worker_tasks.append(task)
            logger.info(f"ğŸ‘· ì›Œì»¤ {i+1} ì‹œì‘")
        
        # í´ë§ íƒœìŠ¤í¬ ì‹œì‘ (ìƒˆ ìš”ì²­ì„ íì— ì¶”ê°€)
        self.polling_task = asyncio.create_task(self._polling(interval))
        
        # ëª¨ë“  íƒœìŠ¤í¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        try:
            await asyncio.gather(*self.worker_tasks, self.polling_task)
        except asyncio.CancelledError:
            pass
    
    def stop(self):
        self.is_running = False
        logger.info("â¹ï¸ ì‹œìŠ¤í…œ ì¤‘ì§€ ì¤‘...")
        
        # ëª¨ë“  ì›Œì»¤ íƒœìŠ¤í¬ ì·¨ì†Œ
        for task in self.worker_tasks:
            if task:
                task.cancel()
        if self.polling_task:
            self.polling_task.cancel()
        
        logger.info(f"â¹ï¸ ì‹œìŠ¤í…œ ì¤‘ì§€ ì™„ë£Œ (íì— ë‚¨ì€ ìš”ì²­: {self.queue.qsize()}ê°œ)")


####

app = FastAPI(title="í•™ì› ë³´ê³ ì„œ ì‹œìŠ¤í…œ")
polling = PollingSystem()

# ExcelFileHandler ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (NotionManager ì£¼ì…)
notion_manager = NotionManager()
excel_handler = ExcelFileHandler(notion_manager=notion_manager)
excel_importer = ExcelImporter(notion_manager)

@app.on_event("startup")
async def startup():
    """ì„œë²„ ì‹œì‘ ì‹œ í´ë§ ë° ì—‘ì…€ íŒŒì¼ ê°ì‹œ ì‹œì‘"""
    asyncio.create_task(polling.start(interval=30))
    asyncio.create_task(excel_file_watcher_worker())

async def excel_file_watcher_worker():
    """ì—‘ì…€ íŒŒì¼ ê°ì‹œ ë° ìë™ ì²˜ë¦¬ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤
    
    10ì´ˆë§ˆë‹¤ ë‹¤ìŒ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰:
    1. ìƒˆ ì—‘ì…€ íŒŒì¼ ê°ì§€ ë° ì €ì¥
    2. ì „ì²˜ë¦¬ (í•©ì¹˜ê¸°, ì¤‘ë³µ ì œê±°, í•„í„°ë§)
    3. Notion DBì— ì¶”ê°€
    4. ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™
    """
    logger.info("ğŸ“‚ ì—‘ì…€ íŒŒì¼ ìë™ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘")
    
    while True:
        try:
            # 1. ìƒˆ ì—‘ì…€ íŒŒì¼ ê°ì§€ ë° ì €ì¥
            result = excel_handler.watch_and_store()
            
            # ê° í´ë”ë³„ë¡œ ì²˜ë¦¬
            for table_type in ["class", "discharge", "student"]:
                if table_type in result and len(result[table_type]) > 0:
                    try:
                        logger.info(f"ğŸ”„ [{table_type}] ìë™ ì²˜ë¦¬ ì‹œì‘...")
                        
                        # 2. ì „ì²˜ë¦¬
                        df = await excel_handler.preprocess_and_merge(table_type)
                        
                        if df is None or df.empty:
                            logger.info(f"âš ï¸ [{table_type}] ì „ì²˜ë¦¬ í›„ ë°ì´í„°ê°€ ì—†ì§€ë§Œ íŒŒì¼ì€ ì´ë™í•©ë‹ˆë‹¤.")
                            # ë°ì´í„°ê°€ ì—†ì–´ë„ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™
                            moved_count = excel_handler.move_processed_files_to_imported(table_type)
                            logger.info(f"âœ… [{table_type}] {moved_count}ê°œ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì™„ë£Œ")
                            continue
                        
                        logger.info(f"âœ… [{table_type}] ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)}ê°œ í–‰")
                        
                        # 3. íì— ì¶”ê°€í•˜ê¸° ì „ì— í•´ë‹¹ í…Œì´ë¸” íƒ€ì…ì˜ íŒŒì¼ë“¤ì„ queued_filesì— ì¶”ê°€
                        for file_info in excel_handler.stored_files[table_type]:
                            file_key = file_info.get("file_key")
                            if file_key:
                                excel_handler.queued_files.add(file_key)
                        
                        # 4. ë°ì´í„° ì…ë ¥ ì‘ì—…ì„ ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€ (ìš°ì„ ìˆœìœ„ 1 = ë†’ìŒ)
                        # í˜„ì¬ stored_filesì— ìˆëŠ” íŒŒì¼ ì •ë³´ë¥¼ ë³µì‚¬ (ì²˜ë¦¬ ì™„ë£Œ í›„ ì´ë™í•˜ê¸° ìœ„í•´)
                        current_file_infos = excel_handler.stored_files[table_type].copy()
                        data_import_request = DataImportRequest(
                            table_type=table_type,
                            dataframe=df,
                            file_infos=current_file_infos  # íŒŒì¼ ì •ë³´ í¬í•¨
                        )
                        polling._queue_order += 1
                        await polling.queue.put((1, polling._queue_order, data_import_request))  # ìš°ì„ ìˆœìœ„ 1
                        logger.info(f"ğŸ“¥ [{table_type}] ë°ì´í„° ì…ë ¥ ì‘ì—… íì— ì¶”ê°€ë¨ (ìš°ì„ ìˆœìœ„: 1, í í¬ê¸°: {polling.queue.qsize()})")
                        
                        # íì— ì¶”ê°€í•œ í›„ í•´ë‹¹ íŒŒì¼ë“¤ì„ stored_filesì—ì„œ ì œê±° (ì²˜ë¦¬ ì™„ë£Œ í›„ ì´ë™í•˜ê¸° ìœ„í•´ ìš”ì²­ì— í¬í•¨ë¨)
                        # ìš”ì²­ì— íŒŒì¼ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì²˜ë¦¬ ì™„ë£Œ ì‹œ í•´ë‹¹ íŒŒì¼ë“¤ë§Œ ì´ë™ë¨
                        for file_info in current_file_infos:
                            file_key = file_info.get("file_key")
                            if file_key:
                                # stored_filesì—ì„œ í•´ë‹¹ íŒŒì¼ ì œê±°
                                excel_handler.stored_files[table_type] = [
                                    f for f in excel_handler.stored_files[table_type]
                                    if f.get("file_key") != file_key
                                ]
                        logger.debug(f"ğŸ”„ [{table_type}] í ì¶”ê°€ í›„ í•´ë‹¹ íŒŒì¼ë“¤ì„ stored_filesì—ì„œ ì œê±° (ìš”ì²­ì— í¬í•¨ë¨)")
                            
                    except Exception as e:
                        logger.error(f"âŒ [{table_type}] ìë™ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                        import traceback
                        logger.error(traceback.format_exc())
                        
        except Exception as e:
            logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ê°ì‹œ ì˜¤ë¥˜: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
        
        # 10ì´ˆë§ˆë‹¤ ìŠ¤ìº”
        await asyncio.sleep(10)

@app.get("/")
async def root():
    return {
        "service": "í•™ì› ë³´ê³ ì„œ ìë™ ìƒì„± ì‹œìŠ¤í…œ",
        "status": "running",
        "ai": "Ollama (qwen3:8b)"
    }

@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.get("/download/{date}/{filename}")
async def download_file(date: str, filename: str):
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸"""
    from fastapi.responses import FileResponse
    
    file_path = config.REPORTS_DIR / date / filename
    
    if not file_path.exists():
        return {"error": "File not found"}, 404
    
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type='application/octet-stream'
    )

@app.post("/webhook/notion")
async def webhook():
    """Notion ì›¹í›… (ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©) - íì— ì¶”ê°€"""
    requests = await polling.orchestrator.notion.get_pending_requests()
    added_count = 0
    for req in requests:
        # ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ì´ì§€ë§Œ ìƒíƒœê°€ ë‹¤ì‹œ "ëŒ€ê¸°ì¤‘"ìœ¼ë¡œ ë³€ê²½ëœ ê²½ìš° ì¬ì²˜ë¦¬
        if req.id in polling.processed_ids:
            logger.info(f"ğŸ”„ ì›¹í›…: ì¬ì²˜ë¦¬ ìš”ì²­ ë°œê²¬ (ìƒíƒœê°€ ë‹¤ì‹œ ëŒ€ê¸°ì¤‘ìœ¼ë¡œ ë³€ê²½ë¨): {req.id}")
            polling.processed_ids.discard(req.id)  # processed_idsì—ì„œ ì œê±°í•˜ì—¬ ì¬ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡
        
        if req.id not in polling.processed_ids:
            # ë³´ê³ ì„œ ìƒì„± ìš”ì²­ì€ ìš°ì„ ìˆœìœ„ 2 (ë‚®ìŒ)
            polling._queue_order += 1
            await polling.queue.put((2, polling._queue_order, req))
            # processed_idsì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ - ì›Œì»¤ì—ì„œ ì²˜ë¦¬í•  ë•Œ ì¶”ê°€
            added_count += 1
            logger.info(f"ğŸ“¥ ì›¹í›…ìœ¼ë¡œ ìƒˆ ìš”ì²­ íì— ì¶”ê°€: {req.id} (ìš°ì„ ìˆœìœ„: 2, í í¬ê¸°: {polling.queue.qsize()})")
    return {"status": "processing", "added_to_queue": added_count}

@app.get("/excel/watch")
async def watch_excel_files():
    """input í´ë”ì˜ ìƒˆ ì—‘ì…€ íŒŒì¼ì„ ê°ì§€í•˜ê³  í´ë”ë³„ë¡œ êµ¬ë³„í•´ì„œ ì €ì¥"""
    try:
        result = excel_handler.watch_and_store()
        
        # ê²°ê³¼ ìš”ì•½ (í´ë”ë³„)
        summary = {}
        data_by_folder = {}
        
        for folder_name, file_list in result.items():
            summary[folder_name] = {
                "file_count": len(file_list),
                "total_rows": sum(file_info["rows"] for file_info in file_list)
            }
            
            # í´ë”ë³„ íŒŒì¼ ì •ë³´ (DataFrame ì œì™¸)
            data_by_folder[folder_name] = [
                {
                    "file_name": file_info["file_name"],
                    "file_path": file_info["file_path"],
                    "folder": file_info["folder"],
                    "rows": file_info["rows"],
                    "columns": file_info["columns"],
                    "read_time": file_info["read_time"]
                }
                for file_info in file_list
            ]
        
        return {
            "status": "success",
            "summary": summary,
            "data_by_folder": data_by_folder
        }
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ê°ì‹œ ì˜¤ë¥˜: {str(e)}")
        return {"status": "error", "message": str(e)}

@app.get("/excel/stored")
async def get_stored_files(table_type: Optional[str] = None):
    """ì €ì¥ëœ ì—‘ì…€ íŒŒì¼ ì •ë³´ ì¡°íšŒ (í´ë”ë³„ë¡œ êµ¬ë³„)"""
    try:
        result = excel_handler.get_stored_files(table_type)
        
        # ê²°ê³¼ ìš”ì•½
        summary = {}
        data_by_folder = {}
        
        for folder_name, file_list in result.items():
            summary[folder_name] = {
                "file_count": len(file_list),
                "total_rows": sum(file_info["rows"] for file_info in file_list)
            }
            
            # í´ë”ë³„ íŒŒì¼ ì •ë³´ (DataFrame ì œì™¸)
            data_by_folder[folder_name] = [
                {
                    "file_name": file_info["file_name"],
                    "file_path": file_info["file_path"],
                    "folder": file_info["folder"],
                    "rows": file_info["rows"],
                    "columns": file_info["columns"],
                    "read_time": file_info["read_time"]
                }
                for file_info in file_list
            ]
        
        return {
            "status": "success",
            "summary": summary,
            "data_by_folder": data_by_folder
        }
    except Exception as e:
        logger.error(f"âŒ ì €ì¥ëœ íŒŒì¼ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return {"status": "error", "message": str(e)}

@app.post("/excel/clear")
async def clear_stored_files(table_type: Optional[str] = None):
    """ì €ì¥ëœ íŒŒì¼ ì •ë³´ ì´ˆê¸°í™”"""
    excel_handler.clear_stored_files(table_type)
    return {
        "status": "success",
        "message": f"{table_type if table_type else 'ëª¨ë“ '} í´ë”ì˜ ì €ì¥ëœ íŒŒì¼ ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

@app.post("/excel/reset")
async def reset_excel_handler():
    """ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ì´ˆê¸°í™” (ëª¨ë“  íŒŒì¼ì„ ë‹¤ì‹œ ì½ì„ ìˆ˜ ìˆë„ë¡)"""
    excel_handler.reset_processed_files()
    return {"status": "success", "message": "ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.post("/excel/preprocess/{table_type}")
async def preprocess_excel_files(table_type: str):
    """ì €ì¥ëœ ì—‘ì…€ íŒŒì¼ë“¤ì„ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±° ë° ë‚ ì§œ í•„í„°ë§ (ì „ì²˜ë¦¬)
    
    Args:
        table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
    """
    try:
        df = await excel_handler.preprocess_and_merge(table_type)
        
        if df is None:
            return {
                "status": "error",
                "message": f"{table_type} í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            }
        
        return {
            "status": "success",
            "table_type": table_type,
            "rows": len(df),
            "columns": list(df.columns),
            "message": f"{table_type} í´ë”ì˜ {len(excel_handler.stored_files[table_type])}ê°œ íŒŒì¼ì„ í•©ì³ì„œ {len(df)}ê°œ í–‰ìœ¼ë¡œ ì „ì²˜ë¦¬ ì™„ë£Œ"
        }
    except Exception as e:
        logger.error(f"âŒ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {"status": "error", "message": str(e)}

@app.post("/excel/import/{table_type}")
async def import_excel_to_notion(table_type: str):
    """ì „ì²˜ë¦¬ëœ ì—‘ì…€ íŒŒì¼ì„ Notionì— ì¶”ê°€í•˜ê³  ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™
    
    Args:
        table_type: í…Œì´ë¸” íƒ€ì… (class, discharge, student)
    """
    try:
        # 1. ì „ì²˜ë¦¬
        logger.info(f"ğŸ”„ [{table_type}] ì „ì²˜ë¦¬ ì‹œì‘...")
        df = await excel_handler.preprocess_and_merge(table_type)
        
        if df is None or df.empty:
            return {
                "status": "error",
                "message": f"{table_type} í´ë”ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ê±°ë‚˜ ì „ì²˜ë¦¬ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            }
        
        logger.info(f"âœ… [{table_type}] ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)}ê°œ í–‰")
        
        # 2. Notionì— ì¶”ê°€
        logger.info(f"ğŸ“¤ [{table_type}] Notion DBì— ì¶”ê°€ ì‹œì‘...")
        added_count = await excel_importer.add_preprocessed_data_to_notion(df, table_type)
        
        if added_count == 0:
            return {
                "status": "error",
                "message": f"{table_type} ë°ì´í„°ë¥¼ Notionì— ì¶”ê°€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            }
        
        logger.info(f"âœ… [{table_type}] Notion DBì— {added_count}ê°œ ì¶”ê°€ ì™„ë£Œ")
        
        # 3. ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™
        logger.info(f"ğŸ“¦ [{table_type}] ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì‹œì‘...")
        moved_count = excel_handler.move_processed_files_to_imported(table_type)
        
        logger.info(f"âœ… [{table_type}] {moved_count}ê°œ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì™„ë£Œ")
        
        return {
            "status": "success",
            "table_type": table_type,
            "preprocessed_rows": len(df),
            "notion_added": added_count,
            "files_moved": moved_count,
            "message": f"{table_type} ì²˜ë¦¬ ì™„ë£Œ: {added_count}ê°œ ë°ì´í„° Notion ì¶”ê°€, {moved_count}ê°œ íŒŒì¼ ì´ë™"
        }
    except Exception as e:
        logger.error(f"âŒ [{table_type}] import ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return {"status": "error", "message": str(e)}

@app.post("/excel/import-all")
async def import_all_excel_to_notion():
    """ëª¨ë“  í´ë”ì˜ ì „ì²˜ë¦¬ëœ ì—‘ì…€ íŒŒì¼ì„ Notionì— ì¶”ê°€í•˜ê³  ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™"""
    try:
        result = {}
        
        for table_type in ["class", "discharge", "student"]:
            try:
                # 1. ì „ì²˜ë¦¬
                logger.info(f"ğŸ”„ [{table_type}] ì „ì²˜ë¦¬ ì‹œì‘...")
                df = await excel_handler.preprocess_and_merge(table_type)
                
                if df is None or df.empty:
                    result[table_type] = {
                        "status": "skipped",
                        "message": "ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ê±°ë‚˜ ì „ì²˜ë¦¬ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                    }
                    continue
                
                logger.info(f"âœ… [{table_type}] ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)}ê°œ í–‰")
                
                # 2. Notionì— ì¶”ê°€
                logger.info(f"ğŸ“¤ [{table_type}] Notion DBì— ì¶”ê°€ ì‹œì‘...")
                added_count = await excel_importer.add_preprocessed_data_to_notion(df, table_type)
                
                # 3. ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™
                logger.info(f"ğŸ“¦ [{table_type}] ì²˜ë¦¬ëœ íŒŒì¼ì„ imported í´ë”ë¡œ ì´ë™ ì‹œì‘...")
                moved_count = excel_handler.move_processed_files_to_imported(table_type)
                
                result[table_type] = {
                    "status": "success",
                    "preprocessed_rows": len(df),
                    "notion_added": added_count,
                    "files_moved": moved_count
                }
                
            except Exception as e:
                logger.error(f"âŒ [{table_type}] ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                result[table_type] = {
                    "status": "error",
                    "message": str(e)
                }
        
        return {
            "status": "success",
            "results": result
        }
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ import ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return {"status": "error", "message": str(e)}

@app.post("/excel/preprocess-all")
async def preprocess_all_excel_files():
    """ëª¨ë“  í´ë”ì˜ ì €ì¥ëœ ì—‘ì…€ íŒŒì¼ë“¤ì„ ì „ì²˜ë¦¬ (í•©ì¹˜ê¸° + ì¤‘ë³µ ì œê±° + ë‚ ì§œ í•„í„°ë§)"""
    try:
        result = await excel_handler.preprocess_all_folders()
        
        summary = {}
        for table_type, df in result.items():
            if df is not None:
                summary[table_type] = {
                    "rows": len(df),
                    "columns": list(df.columns),
                    "file_count": len(excel_handler.stored_files[table_type])
                }
            else:
                summary[table_type] = {
                    "rows": 0,
                    "message": "ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
                }
        
        return {
            "status": "success",
            "summary": summary
        }
    except Exception as e:
        logger.error(f"âŒ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {"status": "error", "message": str(e)}


####

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",  # ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
        port=8000,
        log_level="info"
    )
